{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4320aeb",
   "metadata": {},
   "source": [
    "# Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd03f02a",
   "metadata": {},
   "source": [
    "## Precision\n",
    "\n",
    "$$\n",
    "\\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}\n",
    "$$\n",
    "\n",
    "Precision means that, among positive predictions, how much were actually positive. \n",
    "\n",
    "When the positive is a rare bad thing, and when precision is low, there are too many alerts.\n",
    "\n",
    "## Recall\n",
    "\n",
    "$$\n",
    "\\text{Recall} = \\frac{\\text{TP}}{\\text{FN} + \\text{TP}}\n",
    "$$\n",
    "\n",
    "Recall means that, among actual positive response, how much we were able to predict as positive. \n",
    "\n",
    "When the positive is a rare bad thing, and when recall is low, we are missing too many times, and it's damaging our sysmte.\n",
    "\n",
    "## Problem\n",
    "\n",
    "Given a confusion matrix, write a function to compute precision and recall. The vertical represents actual positive, negative. The horizontal represents predicted positive and negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cae80e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8768115942028986, 0.9307692307692308)\n"
     ]
    }
   ],
   "source": [
    "conf_mat = [\n",
    "    [121, 9],\n",
    "    [17, 144]\n",
    "]\n",
    "\n",
    "\n",
    "def precision_recall(P):\n",
    "    # Precision is about prediction\n",
    "    precision = P[0][0] / (P[0][0] + P[1][0])\n",
    "    \n",
    "    # Recall is about actual\n",
    "    recall = P[0][0] / (P[0][0] + P[0][1])\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "print(precision_recall(conf_mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ee3ac2",
   "metadata": {},
   "source": [
    "## Spam classifier\n",
    "\n",
    "Your task is to build a spam classifier for emails. What metrics would you use to track accuracy and validity of the model you build?\n",
    "\n",
    "This is an imbalanced-class binary classification problem. Define the following things.\n",
    "\n",
    "True positive is the spam prediction to the actual spam data. True negative is the non-spam prediction to the actual non-spam data. False positive is the spam prediction to the actual non-spam data. False negative is the non-spam prediction to the actual spam data. \n",
    "\n",
    "Accuracy is the sum of true positive and true negative divided by the number of data. But it's not a good metric for imbalanced-class binary classification problem, because you can get a high accuracy with a model which predicts all the emails to be non-spam.\n",
    "\n",
    "Use the following.\n",
    "\n",
    "Precision is the true positive divided by the sum of true positive and false positive. Recall is the true positive divided by the sum of true positive and false negative. F1 score is the harmonic mean of precision and recall, which is useful to get a single score. \n",
    "\n",
    "AUC is the area under the curve. The curve is the plot by true positive on X axis and false positive on Y axis for different threshold values. \n",
    "\n",
    "F1 score is a good metric for determining the model capability for imbalanced-class binary classificaiton. AUC is a good metric to compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61edcbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38b96c3d",
   "metadata": {},
   "source": [
    "## Resource\n",
    "\n",
    "- [Precision and recall](https://en.wikipedia.org/wiki/Precision_and_recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-machine-learning",
   "language": "python",
   "name": "env-machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
