{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8539b789",
   "metadata": {},
   "source": [
    "# SHAP (SHapley Additive exPlanations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc3ede8",
   "metadata": {},
   "source": [
    "## Idea\n",
    "\n",
    "SHAP is a method to make explanation by using Shapley values, so it's good to understand Shapley value first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c065f01",
   "metadata": {},
   "source": [
    "## Shapley value\n",
    "\n",
    "$F$ is the set of all features.\n",
    "\n",
    "$S$ is all feature subsets.\n",
    "\n",
    "$f$ is model.\n",
    "\n",
    "$f_{S \\cup \\{i\\}}$ is a trained model which includes $i$th feature.\n",
    "\n",
    "$f_{S}$ is a trained model which doesn't include $i$th feature.\n",
    "\n",
    "$x_{S \\cup \\{ i \\}}$ is the values of the features including $i$th feature.\n",
    "\n",
    "$x_{S}$ is the values of the features not including $i$th feature.\n",
    "\n",
    "$f_{S \\cup \\{i\\}} (x_{S \\cup \\{ i \\}})$ is a prediction by including $i$th feature.\n",
    "\n",
    "$f_{S} (x_{S})$ is a prediction by not including $i$th feature.\n",
    "\n",
    "$f_{S \\cup \\{i\\}} (x_{S \\cup \\{ i \\}}) - f_{S} (x_{S})$ is the difference between the predictions by the 2 models.\n",
    "\n",
    "The vertical lines of $|F|$ represents the cardianlity, meaning the number of elements of set $F$.\n",
    "\n",
    "$\\frac{|S|!(|F| - |S| - 1)!}{|F|!}$ is a weight that we can compute from the number of features.\n",
    "\n",
    "$\\sum_{S \\subseteq F \\backslash \\{ i \\}}$ is summing over the combination of features which doesn't include $i$th feature but we are adding $i$th feature.\n",
    "\n",
    "$\\sum_{S \\subseteq F \\backslash \\{ i \\}} \\frac{|S|!(|F| - |S| - 1)!}{|F|!}$ will be 1, so we can do a weighted average.\n",
    "\n",
    "$S \\subseteq F$ means $S$ is a subset of $F$ and $S$ and $F$ can be equal. \n",
    "\n",
    "$S \\subseteq F \\backslash \\{ i \\}$ means that $S$ is a subset of $F$ but we exclude $i$th feature from $S$. Even if $S \\subseteq F$, we won't use a case where $S = F$ and instead use $S \\subseteq F \\backslash \\{ i \\}$ because we are interested in the additional effect of $i$th feature.\n",
    "\n",
    "$\\backslash$ means relative complement. $A \\backslash B$ means objects that belong to $A$ and not to $B$. For example, $A$ = {1, 2}, $B$ = {2, 3}, $A \\backslash B$ = {1}. \n",
    "\n",
    "$\\phi_i$ is Shapley value of $i$th feature, computed by the following formula.\n",
    "\n",
    "$$\n",
    "\\phi_i = \\sum_{S \\subseteq F \\backslash \\{i\\}} \\frac{|S|!(|F| - |S| - 1)!}{|F|!} \\left[ f_{S \\cup \\{i\\}} (x_{S \\cup \\{ i \\}}) - f_{S} (x_{S}) \\right]\n",
    "$$\n",
    "\n",
    "It means that Shapley value of $i$th feature is a weighted average of prediction differences between a model including $i$th feature and a model not including $i$th feature.\n",
    "\n",
    "For example,\n",
    "\n",
    "When we have 3 features and we wanna know the Shapley value of the 1st feature.\n",
    "\n",
    "$F = \\{ F_1, F_2, F_3 \\}, |F| = 3$.\n",
    "\n",
    "When we have 3 features, $S$ is a set of the followings\n",
    "\n",
    "$S_1 = \\{ \\}, |S| = 0$\n",
    "\n",
    "$S_2 = \\{ F_1 \\}, |S| = 1$\n",
    "\n",
    "$S_3 = \\{ F_2 \\}, |S| = 1$\n",
    "\n",
    "$S_4 = \\{ F_3 \\}, |S| = 1$\n",
    "\n",
    "$S_5 = \\{ F_1, F_2 \\}, |S| = 2$\n",
    "\n",
    "$S_6 = \\{ F_1, F_3 \\}, |S| = 2$\n",
    "\n",
    "$S_7 = \\{ F_2, F_3 \\}, |S| = 2$\n",
    "\n",
    "$S_8 =  \\{ F_1, F_2, F_3 \\}, |S| = 3$\n",
    "\n",
    "$S \\subseteq F \\backslash \\{1\\} = \\{ S_1, S_3, S_4, S_7 \\}$, because by adding $F_1$, we have $S_1 \\rightarrow S_2$, $S_3 \\rightarrow S_5$, $S_4 \\rightarrow S_6$, and $S_7 \\rightarrow S_8$\n",
    "\n",
    "We need to train 8 different models for $S_1$ through $S_8$ features.\n",
    "\n",
    "We check the way to compute weights below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a8af6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F: 3, S: 0\n",
      "|F|!: 6\n",
      "|S|!: 1\n",
      "(|F| - |S| - 1)!: 2\n",
      "|S|!*(|F| - |S| - 1)! / |F|!: 1*2 / 6 = 2 / 6\n",
      "\n",
      "0.3333333333333333\n",
      "0.16666666666666666\n",
      "0.3333333333333333\n",
      "\n",
      "Sum of weights: 1.0\n"
     ]
    }
   ],
   "source": [
    "from math import factorial\n",
    "\n",
    "\n",
    "def compute_weight(F, S, output=False):\n",
    "\n",
    "    if output:\n",
    "        print(f'F: {F}, S: {S}')\n",
    "        print(f'|F|!: {factorial(F)}')\n",
    "        print(f'|S|!: {factorial(S)}')\n",
    "        print(f'(|F| - |S| - 1)!: {factorial(F - S - 1)}')\n",
    "        print(f'|S|!*(|F| - |S| - 1)! / |F|!: {factorial(S)}*{factorial(F - S - 1)} / {factorial(F)} = {factorial(S) * factorial(F - S - 1)} / {factorial(F)}')\n",
    "        print()\n",
    "    \n",
    "    return (factorial(S) * factorial(F - S - 1)) / factorial(F)\n",
    "\n",
    "\n",
    "print(compute_weight(3, 0, True))\n",
    "print(compute_weight(3, 1))\n",
    "print(compute_weight(3, 2))\n",
    "print()\n",
    "\n",
    "w_1 = compute_weight(3, 0)\n",
    "w_2 = compute_weight(3, 1)\n",
    "w_3 = compute_weight(3, 1)\n",
    "w_4 = compute_weight(3, 2)\n",
    "\n",
    "print(f'Sum of weights: {w_1 + w_2 + w_3 + w_4}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f391044",
   "metadata": {},
   "source": [
    "## SHAP\n",
    "\n",
    "$f$ is our machine learning model that we want to explain. \n",
    "\n",
    "$f(x)$ is the prediction of the machine learning model.\n",
    "\n",
    "$g(x)$ approximates $f(x)$. \n",
    "\n",
    "We call $g$ the **explanation model**.\n",
    "\n",
    "$g$ is the linear combination of Shapley values.\n",
    "\n",
    "$\\phi_0$ is the null model output.\n",
    "\n",
    "We call this method the **additive feature attribution methods** because of the linear combination of Shapley values of each feature.\n",
    "\n",
    "\n",
    "xxx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a0dd1ed",
   "metadata": {},
   "source": [
    "## Resource\n",
    "\n",
    "- [SHAP Values Explained Exactly How You Wished Someone Explained to You](https://towardsdatascience.com/shap-explained-the-way-i-wish-someone-explained-it-to-me-ab81cc69ef30)\n",
    "- [Black-Box models are actually more explainable than a Logistic Regression](https://towardsdatascience.com/black-box-models-are-actually-more-explainable-than-a-logistic-regression-f263c22795d)\n",
    "- [Math Symbols List](https://www.rapidtables.com/math/symbols/Basic_Math_Symbols.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-machine-learning",
   "language": "python",
   "name": "env-machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
