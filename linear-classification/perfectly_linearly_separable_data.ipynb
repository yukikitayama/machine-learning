{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cb3096a",
   "metadata": {},
   "source": [
    "# Perfectly Linearly Separable Data\n",
    "\n",
    "Given a dataset of perfectly linearly separable data, what would happen when you run logistic regression?\n",
    "\n",
    "We perform the gradient descent to find the maxima of the likelihood function. In inperfectly linearly separable data, this maxima exists. But in perfectly linearly separable data, there is not this peak, so the likelihood functions infinitely slopes upwards. The algorithm keeps searching a higher slope and it doesn't converge.\n",
    "\n",
    "Another way of looking at it is that logistic regression will have an infinite number of decision boundaries, so that we cannot define a set of the coefficient parameters for logistic regerssion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-machine-learning",
   "language": "python",
   "name": "env-machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
