{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional RNN and GRU Cells for Digit recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1)\n",
      "(42000, 10)\n"
     ]
    }
   ],
   "source": [
    "y = train['label'].values.reshape((-1, 1))\n",
    "X = train.drop('label', axis = 1).values\n",
    "y_oh = to_categorical(y)\n",
    "print(y.shape)\n",
    "print(y_oh.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33600, 784) (8400, 784) (33600, 10) (8400, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_vali, y_train, y_vali = train_test_split(X, y_oh, test_size = 0.2, random_state = 42)\n",
    "print(X_train.shape, X_vali.shape, y_train.shape, y_vali.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional RNN with GRU cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    idx = np.arange(0, len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[i] for i in idx]\n",
    "    labels_shuffle = [labels[i] for i in idx]\n",
    "    \n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "time_steps = 784\n",
    "# batch_size = 128\n",
    "batch_size = 280\n",
    "num_classes = 10\n",
    "# hidden_layer_size = 32\n",
    "hidden_layer_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_inputs = tf.placeholder(tf.float32, shape = [batch_size, time_steps, 1])\n",
    "_labels = tf.placeholder(tf.float32, shape = [batch_size, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = X_vali[:batch_size].reshape((-1, time_steps, 1))\n",
    "validation_label = y_vali[:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 784, 1)\n",
      "(280, 10)\n"
     ]
    }
   ],
   "source": [
    "print(validation_data.shape)\n",
    "print(validation_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-11-c70ab40fbee7>:3: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-11-c70ab40fbee7>:14: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\yukic\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\yukic\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"biGRU\"):\n",
    "    with tf.variable_scope('forward'):\n",
    "        gru_fw_cell = tf.contrib.rnn.GRUCell(hidden_layer_size)\n",
    "        gru_fw_cell = tf.contrib.rnn.DropoutWrapper(gru_fw_cell)\n",
    "\n",
    "    with tf.variable_scope('backward'):\n",
    "        gru_bw_cell = tf.contrib.rnn.GRUCell(hidden_layer_size)\n",
    "        gru_bw_cell = tf.contrib.rnn.DropoutWrapper(gru_bw_cell)\n",
    "\n",
    "    outputs, states = tf.nn.bidirectional_dynamic_rnn(cell_fw = gru_fw_cell,\n",
    "                                                      cell_bw = gru_bw_cell,\n",
    "                                                      inputs = _inputs,\n",
    "                                                      dtype = tf.float32,\n",
    "                                                      scope = \"BiGRU\")\n",
    "\n",
    "states = tf.concat(values = states, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-40a0e8d8136c>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weights = {'linear_layer': tf.Variable(tf.truncated_normal([2 * hidden_layer_size, num_classes], mean = 0, stddev = 0.01))}\n",
    "biases = {'linear_layer': tf.Variable(tf.truncated_normal([num_classes], mean = 0, stddev = 0.01))}\n",
    "\n",
    "final_output = tf.matmul(states, weights[\"linear_layer\"]) + biases[\"linear_layer\"]\n",
    "softmax = tf.nn.softmax_cross_entropy_with_logits(logits = final_output, labels = _labels)\n",
    "cross_entropy = tf.reduce_mean(softmax)\n",
    "\n",
    "train_step = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(_labels, 1), tf.argmax(final_output, 1))\n",
    "accuracy = (tf.reduce_mean(tf.cast(correct_prediction, tf.float32))) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter = 0 Loss = 2.302186 Accuracy = 8.57143 Validation accuracy = 12.14286\n",
      "Iter = 1000 Loss = 1.398895 Accuracy = 40.35714 Validation accuracy = 44.28571\n",
      "Iter = 2000 Loss = 1.118548 Accuracy = 59.64286 Validation accuracy = 61.78572\n",
      "Iter = 3000 Loss = 0.926202 Accuracy = 65.35714 Validation accuracy = 66.42857\n",
      "Iter = 4000 Loss = 0.935283 Accuracy = 67.14285 Validation accuracy = 68.92857\n",
      "Iter = 5000 Loss = 0.745229 Accuracy = 76.07143 Validation accuracy = 74.28571\n",
      "Iter = 6000 Loss = 0.683156 Accuracy = 76.42857 Validation accuracy = 76.42857\n",
      "Iter = 7000 Loss = 0.777725 Accuracy = 74.64285 Validation accuracy = 71.78571\n",
      "Iter = 8000 Loss = 0.656688 Accuracy = 78.57143 Validation accuracy = 81.07143\n",
      "Iter = 9000 Loss = 0.580691 Accuracy = 82.14286 Validation accuracy = 79.28572\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(10000):\n",
    "    batch_x, batch_y = next_batch(batch_size, X_train, y_train)\n",
    "    batch_x = batch_x.reshape((batch_size, time_steps, 1))\n",
    "    sess.run(train_step, feed_dict = {_inputs: batch_x,\n",
    "                                      _labels: batch_y})\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        acc, loss = sess.run([accuracy, cross_entropy], feed_dict = {_inputs: batch_x,\n",
    "                                                                     _labels: batch_y})\n",
    "        val_acc = sess.run(accuracy, feed_dict = {_inputs: validation_data,\n",
    "                                                  _labels: validation_label})\n",
    "        print(\"Iter = \" + str(i) + \" Loss = {:.6f}\".format(loss) + \" Accuracy = {:.5f}\".format(acc) + \n",
    "              \" Validation accuracy = {:.5f}\".format(val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ter = 0 Loss = 2.301327 Accuracy = 11.71875 Validation accuracy = 7.03125\n",
    "Iter = 1000 Loss = 1.559995 Accuracy = 39.06250 Validation accuracy = 47.65625\n",
    "Iter = 2000 Loss = 1.138049 Accuracy = 53.90625 Validation accuracy = 67.96875\n",
    "Iter = 3000 Loss = 0.874593 Accuracy = 71.09375 Validation accuracy = 75.78125\n",
    "Iter = 4000 Loss = 0.569118 Accuracy = 80.46875 Validation accuracy = 78.12500\n",
    "Iter = 5000 Loss = 0.903366 Accuracy = 66.40625 Validation accuracy = 71.87500\n",
    "Iter = 6000 Loss = 0.594484 Accuracy = 78.12500 Validation accuracy = 86.71875\n",
    "Iter = 7000 Loss = 0.431124 Accuracy = 83.59375 Validation accuracy = 86.71875\n",
    "Iter = 8000 Loss = 0.495741 Accuracy = 84.37500 Validation accuracy = 85.93750\n",
    "Iter = 9000 Loss = 0.318530 Accuracy = 91.40625 Validation accuracy = 86.71875"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n",
      "(28000, 784, 1)\n"
     ]
    }
   ],
   "source": [
    "X_test = test.values.reshape((-1, time_steps, 1))\n",
    "print(test.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "\n",
    "for i in range(X_test.shape[0]//batch_size):\n",
    "    X_test_iter = X_test[(i*batch_size):((i+1)*batch_size)]\n",
    "    y_pred = sess.run(tf.argmax(final_output, 1), feed_dict = {_inputs: X_test_iter})\n",
    "    \n",
    "    y_pred_list.append(y_pred)\n",
    "    \n",
    "y_pred_list = [item for sublist in y_pred_list for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000,)\n",
      "28000\n"
     ]
    }
   ],
   "source": [
    "test_id = np.arange(1, X_test.shape[0] + 1, 1)\n",
    "print(test_id.shape)\n",
    "print(len(y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      0\n",
       "4        5      2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame(data = {'ImageId': test_id,\n",
    "                           'Label': y_pred_list})\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('C:\\\\Users\\\\yukic\\\\Documents\\\\kaggle\\\\digit_recognizer\\\\submission_190910.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
