{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a25c9c9",
   "metadata": {},
   "source": [
    "# Neural Network Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2895f0",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "Adding regularization to the cost function of neural network is,\n",
    "\n",
    "$$\n",
    "\\mathcal{J}(W, b) = \\frac{1}{m} \\sum_{i = 1}^{m} \\mathcal{L}(\\hat{y}^{(i)}, y^{(i)}) + \\frac{\\lambda}{2m} \\sum_{l = 1}^{L} \\| W^{[l]} \\|^2\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\| W^{[l]} \\|_{F}^2 = \\sum_{i = 1}^{n^{[l]}} \\sum_{j = 1}^{n^{[l - 1]}} (w_{i, j}^{[l]})^2\n",
    "$$\n",
    "\n",
    "Because we wanna minimize $\\mathcal{J}$, if we set a large $\\lambda$, $W$ will be close to 0, because otherwise, $\\mathcal{J}$ won't be small.\n",
    "\n",
    "We have double sums because $W$ is a **matrix** with weights, and its dimension is,\n",
    "\n",
    "$$\n",
    "W: (n^{[l]} \\times n^{[l - 1]})\n",
    "$$\n",
    "\n",
    "So in one weight matrix, we square each element of weights and sum up to all the rows and columns directions to make it a single **scalar**. This $\\| W^{[l]} \\|_{F}^2$ is called **Frobenius norm**.\n",
    "\n",
    "**Gradient descent** with regularization will be the following. First, we get derivative of cost function with respect to weight. $\\alpha$ is a learning rate. $\\lambda$ is a **regularization parameter** to control how much effective the regularization is. $m$ is the number of examples. Let $\\text{backprops}$ be a sequence of partial derivatives obtained in **backward propagation**.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\mathcal{J}}{\\partial W} = \\text{backprops} + \\frac{\\lambda}{m} W\n",
    "$$\n",
    "\n",
    "So the gradient descent will be,\n",
    "\n",
    "$$\n",
    "W = W - \\alpha \\frac{\\partial \\mathcal{J}}{\\partial W}\n",
    "$$\n",
    "$$\n",
    "= W - \\alpha \\left[ \\text{backprops} + \\frac{\\lambda}{m} W \\right]\n",
    "$$\n",
    "$$\n",
    "= W - \\alpha \\frac{\\lambda}{m} W - \\alpha \\left[ \\text{backprops} \\right]\n",
    "$$\n",
    "$$\n",
    "= (1 - \\frac{\\alpha \\lambda}{m}) W - \\alpha \\left[ \\text{backprops} \\right]\n",
    "$$\n",
    "\n",
    "Typically $\\frac{\\alpha \\lambda}{m} \\ll 1$, so with the regularization parameter, it has an effect of making $W$ smaller, because subtracting some number from 1. It is the same effect as we see in the regularization in linear regression to make paramters small. Because of regularization, weights get smaller, so some people say it's **weight decay**. \n",
    "\n",
    "**Dropout** is another to introduce regularization by making a neural network small by randomly making some weights 0. \n",
    "\n",
    "In image recognition tasks, **data augmentation** can be used as regularization by adding noise, changing angles, zoom in/out and flipping, then we can add more challenging data or diverse data to training data.\n",
    "\n",
    "## Normalization\n",
    "\n",
    "After normalizing the input, the contour of the cost function will be more sphere than elongated ellipse shape, so the gradient descent will be more straight to the minimum. But in the elongated ellipse, the gradient descent is easy to offshoot and oscillate.\n",
    "\n",
    "Notice that the same mean and variance used in the training data should be applied to the test data. No re-calculation of mean and variance from the test data.\n",
    "\n",
    "## Weight Initialization\n",
    "\n",
    "Vanishing/exploding gradients\n",
    "\n",
    "He initialization for ReLU\n",
    "\n",
    "Xavier initialization for tanh\n",
    "\n",
    "## Gradient Checking\n",
    "\n",
    "**Grad check**\n",
    "\n",
    "## Batch\n",
    "\n",
    "Use **epoch** to describe passing through the entire training set.\n",
    "\n",
    "**Batch gradient descent** uses the entire data per gradient descent. So 1 gradient descent per epoch.\n",
    "\n",
    "**Mini-batch gradient descent** uses a part of all the data per gradient descent, so multiple gradient descents per epoch.\n",
    "\n",
    "People use mini-batch gradient descent because it runs faster.\n",
    "\n",
    "When mini-batch size is 1, it's called **stochastic gradient descent**.\n",
    "\n",
    "When training set is huge, we should use mini-batch, but if the training set is small, we are fine to use batch gradient descent.\n",
    "\n",
    "People believe that computers will run faster if we use the power of two, for example, $64 = 2^6$, $128 = 2^7$, $256 = 2^8$, $512 = s^9$.\n",
    "\n",
    "## Exponentially weighted moving average\n",
    "\n",
    "$$\n",
    "v_t = \\beta v_{t - 1} + (1 - \\beta) \\theta_{t}\n",
    "$$\n",
    "\n",
    "Where\n",
    "\n",
    "$$\n",
    "\\beta = 0.9\n",
    "$$\n",
    "\n",
    "$\\theta_t$ is the actual data which will be turned into moving average.\n",
    "\n",
    "$v_t$ as approximately average over $\\approx \\frac{1}{1 - \\beta}$ number of data. For example, when $\\beta = 0.9$\n",
    "\n",
    "$$\n",
    "\\frac{1}{1 - 0.9} = \\frac{1}{0.1} = 10\n",
    "$$\n",
    "\n",
    "So it's the average over the last 10 data. When $\\beta = 0.98$\n",
    "\n",
    "$$\n",
    "\\frac{1}{1 - 0.98} = \\frac{1}{0.02} = 50\n",
    "$$\n",
    "\n",
    "- If $\\beta$ is large, average over more data, moving average is smoother.\n",
    "- If $\\beta$ is small, average over less data, moving average is more spiky.\n",
    "\n",
    "When $\\beta = 0.9$\n",
    "\n",
    "$$\n",
    "v_3 = 0.9 v_2 + 0.1 \\theta_3\n",
    "$$\n",
    "$$\n",
    "v_2 = 0.9 v_1 + 0.1 \\theta_2\n",
    "$$\n",
    "$$\n",
    "v_1 = 0.9 v_0 + 0.1 \\theta_1\n",
    "$$\n",
    "\n",
    "By substituting $v_2$ and $v_1$ into $v_3$ equation,\n",
    "\n",
    "$$\n",
    "v_3 = 0.9 (0.9 \\times (0.9 v_0 + 0.1 \\theta_1) + 0.1 \\theta_2) + 0.1 \\theta_3\n",
    "$$\n",
    "$$\n",
    "= 0.9^3 v_0 + 0.9^2 \\times 0.1 \\theta_1 + 0.9 \\times 0.1 \\theta_2 + 0.1 \\theta_3\n",
    "$$\n",
    "\n",
    "By rearranging,\n",
    "\n",
    "$$\n",
    "= 0.1 \\theta_3 + 0.1 \\times 0.9 \\theta_2 + 0.1 \\times 0.9^2 \\theta_1 + 0.9^3 v_0\n",
    "$$\n",
    "$$\n",
    "= 0.1 \\times 0.9^0 \\theta_3 + 0.1 \\times 0.9^1 \\theta_2 + 0.1 \\times 0.9^2 \\theta_1 + 0.9^3 v_0\n",
    "$$\n",
    "\n",
    "Because we choose $\\beta \\le 1$, if we take power of $\\beta$, it will get smaller. So exponentially weighted moving average has the effect of putting more weight on the recent data (e.g. $\\theta_3$) and less weight on the old data (e.g. $\\theta_1$)\n",
    "\n",
    "**Bias correction**. This is because the above uses $v_0 = 0$. The initial phase of moving average is small numbers. The correction uses $\\frac{v_t}{1 - \\beta^t}$. In practice, people don't do this, because the bias will be corrected after initial iterations.\n",
    "\n",
    "\n",
    "https://www.coursera.org/learn/deep-neural-network/lecture/lXv6U/normalizing-inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aef2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize exponentially moving average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17b9b4f",
   "metadata": {},
   "source": [
    "By using mini-batch gradient descent, optimization will oscillate because of the random chance of the mini-batch sample of the training set. Smoothing this oscillation make the learning faster. Oscillation appears because the gradients oscillate. So the idea is to apply the exponetially weighted moving average to the noisy gradients. This approach is called **gradient descent with momentum**.\n",
    "\n",
    "In a basic form, $\\alpha$ is learning rate, we have,\n",
    "\n",
    "$$\n",
    "W = W - \\alpha \\frac{\\partial \\mathcal{J}}{\\partial W}\n",
    "$$\n",
    "\n",
    "But in gradient descent with momentum, after getting derivative, we first apply exponentially weighted moving average to gradients to get the average gradients, and then do gradient descent with the average gradient.\n",
    "\n",
    "$$\n",
    "v_{\\frac{\\partial \\mathcal{J}}{\\partial W}, t} = \\beta v_{\\frac{\\partial \\mathcal{J}}{\\partial W}, (t - 1)} + (1 - \\beta) \\frac{\\partial \\mathcal{J}}{\\partial W}_t\n",
    "$$\n",
    "$$\n",
    "W = W - \\alpha v_{\\frac{\\partial \\mathcal{J}}{\\partial W}, t}\n",
    "$$\n",
    "\n",
    "Typical choice for $\\beta$ is 0.9, the average of the last 10 gradients.\n",
    "\n",
    "https://www.coursera.org/learn/deep-neural-network/lecture/y0m1f/gradient-descent-with-momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e8eb02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-machine-learning",
   "language": "python",
   "name": "env-machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
