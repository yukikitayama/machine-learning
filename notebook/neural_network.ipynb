{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b087c50",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b81395",
   "metadata": {},
   "source": [
    "## Concept\n",
    "\n",
    "If network has $s_j$ units in layer $j$ and $s_{j + 1}$ units inlayer $j + 1$, then $\\Theta^{(j)}$ will be of dimension $s_{j + 1} \\times (s_{j} + 1)$. $+ 1$ because $s_{j + 1}$ has additional **bias unit**. $\\Theta^{(j)}$ is a matrix of **weights** controlling function mapping from layer $j$ to layer $j + 1$.\n",
    "\n",
    "When a neural network has **no hidden layers** and has only **one unit in output layer**,\n",
    "\n",
    "- If output layer is **linear activation**, it's **linear regression** because $y = I (\\Theta x) = \\Theta x$.\n",
    "- If output layer is **sigmoid activation**, it's **logistic regression** because $y = \\sigma(\\Theta x)$ where $\\sigma = \\frac{1}{1 + e^{(-\\Theta x)}}$.\n",
    "\n",
    "## Cost Function\n",
    "\n",
    "In **multi-class classification** where $n$ is the number of data, $L$ is the number of layers in neural network including input and output layers, $s_{l}$ is the number of units (not including bias unit) in layer $l$, $K$ is the number of classes, $\\Theta$ is the weight matrices, $h_{\\Theta}(x)$ is the output of neural network and $\\in \\mathbb{R}^K$, $(h_{\\Theta}(x))_i$ is $i^{th}$ output, and $J(\\Theta)$ is the cost.\n",
    "\n",
    "$$\n",
    "J(\\Theta) = - \\frac{1}{n} \\left[ \\sum_{i = 1}^{n} \\sum_{k = 1}^{K} y_{k}^{(i)} \\log (h_{\\Theta}(x^{(i)}))_{k} + (1 - y_{k}^{(i)}) \\log (1 - (h_{\\Theta}(x^{(i)}))_{k}) \\right] + \\frac{\\lambda}{2n} \\sum_{l = 1}^{L} \\sum_{i = 1}^{s_{l}} \\sum_{j = 1}^{s_{l + 1}} (\\Theta_{ji}^{(l)})^2\n",
    "$$\n",
    "\n",
    "This math takes the form of,\n",
    "\n",
    "$$\n",
    "\\text{Regularized cost} = \\text{Cost} + \\lambda \\times \\text{Regularization}\n",
    "$$\n",
    "\n",
    "The first $\\sum_{i = 1}^{n} \\sum_{k = 1}^{K} y_{k}^{(i)}$ part says that we get the **log-likelihood** by each class and sum up all the $n$ items and divide it by $n$ to get the average cost.\n",
    "\n",
    "The second $\\sum_{l = 1}^{L} \\sum_{i = 1}^{s_{l}} \\sum_{j = 1}^{s_{l + 1}}$ says that we get all the weight parameters in the neural network to regularize them.\n",
    "\n",
    "## Backpropagation\n",
    "\n",
    "**Backpropagation** is neural network terminology for minimizing the cost function. The goal is to compute,\n",
    "\n",
    "$$\n",
    "\\underset{\\Theta}{\\min} J(\\Theta)\n",
    "$$\n",
    "\n",
    "It means that we want to minimize the cost function $J$ using an optimal set of parameters $\\Theta$.\n",
    "\n",
    "## Gradient Descent\n",
    "\n",
    "### Logistic Regression Gradient Descent\n",
    "\n",
    "$$\n",
    "z = w^T x + b\n",
    "$$\n",
    "$$\n",
    "\\hat{y} = a = \\sigma(z)\n",
    "$$\n",
    "$$\n",
    "\\mathcal{L}(a, y) = -(y \\log(a) + (1 - y) \\log(1 - a))\n",
    "$$\n",
    "\n",
    "When $p = 2$,\n",
    "\n",
    "Computation graph is,\n",
    "\n",
    "$x_1, w_1, x_2, w_2, b \\rightarrow z = w_1 x_1 + w_2 x_2 + b \\rightarrow \\hat{y} = a = \\sigma(z) \\rightarrow \\mathcal{L}(a, y)$ \n",
    "\n",
    "By changing $w_1, w_2, b$, we want to reduce $\\mathcal{L}(a, y)$\n",
    "\n",
    "The loss function is,\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(a, y) = -(y \\log(a) + (1 - y) \\log(1 - a))\n",
    "$$\n",
    "\n",
    "Derivative of loss function with respect to $a$ is, by derivative of log and chain rule,\n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{da} = -y \\frac{1}{a} - (1 - y) \\frac{1}{1 - a} (-1)\n",
    "$$\n",
    "$$\n",
    "= \\frac{-y}{a} + \\frac{1 - y}{1 - a}\n",
    "$$\n",
    "$$\n",
    "= \\frac{-y(1 - a)}{a(1 - a)} + \\frac{(1 - y)a}{(1 - a)a}\n",
    "$$\n",
    "$$\n",
    "= \\frac{-y + ay + a - ay}{a(1 - a)}\n",
    "$$\n",
    "\n",
    "So we have,\n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{da} = \\frac{a - y}{a(1 - a)}\n",
    "$$\n",
    "\n",
    "Next, derivative of $a$ with respect to $z$, because $a = \\sigma(z)$,\n",
    "\n",
    "$$\n",
    "\\frac{da}{dz} = \\frac{d}{dz} \\sigma(z)\n",
    "$$\n",
    "\n",
    "Because derivative of sigmoid function is $\\frac{d}{dz} \\sigma(z) = \\sigma(z)(1 - \\sigma(z)$ and $a = \\sigma(z)$,\n",
    "\n",
    "$$\n",
    "\\frac{da}{dz} = a (1 - a)\n",
    "$$\n",
    "\n",
    "Finally, derivative of loss function with respect to $z$ is, by chain rule,\n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{dz} = \\frac{d \\mathcal{L}}{da} \\frac{da}{dz}\n",
    "$$\n",
    "$$\n",
    "= \\frac{a - y}{a(1 - a)} a (1 - a)\n",
    "$$\n",
    "\n",
    "So we have,\n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{dz} = a - y \n",
    "$$\n",
    "\n",
    "Now, we get derivative with respect to parameters, $\\frac{d \\mathcal{L}}{d w_1}$, $\\frac{d \\mathcal{L}}{d w_2}$, and $\\frac{d \\mathcal{L}}{db}$. By chain rule,\n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{d w_1} = \\frac{d \\mathcal{L}}{da} \\frac{da}{dz} \\frac{dz}{dw_1}\n",
    "$$\n",
    "\n",
    "Because $z = w_1 x_1 + w_2 x_2 + b$, derivative of $z$ with respect to $w_1$ is,\n",
    "\n",
    "$$\n",
    "\\frac{dz}{dw_1} = x_1\n",
    "$$\n",
    "\n",
    "Likewise,\n",
    "\n",
    "$$\n",
    "\\frac{dz}{dw_2} = x_2\n",
    "$$\n",
    "$$\n",
    "\\frac{dz}{db} = 1\n",
    "$$\n",
    "\n",
    "So finally derivative of loss function is each parameter is,\n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{dw_1} = \\frac{a - y}{a(1 - a)} a (1 - a) x_1 = (a - y) x_1\n",
    "$$\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{dw_2} = \\frac{a - y}{a(1 - a)} a (1 - a) x_2 = (a - y) x_2\n",
    "$$\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{db} = \\frac{a - y}{a(1 - a)} a (1 - a) 1 = (a - y)\n",
    "$$\n",
    "\n",
    "Because we got the gradient with respect to parameters, finally we can do gradient descent by\n",
    "\n",
    "$$\n",
    "w_1 = w_1 - \\alpha \\frac{d \\mathcal{L}}{d w_1} = w_1 - \\alpha (a - y) x_1\n",
    "$$\n",
    "$$\n",
    "w_2 = w_2 - \\alpha \\frac{d \\mathcal{L}}{d w_2} = w_2 - \\alpha (a - y) x_2\n",
    "$$\n",
    "$$\n",
    "b = b - \\alpha \\frac{d \\mathcal{L}}{d b} = b - \\alpha (a - y)\n",
    "$$\n",
    "\n",
    "### Pseudocode for Gradient Descent in Neural Network\n",
    "\n",
    "When neural network architecture uses logistic regression, $p = 2$, $n$ is the number of data, and use the simplified expression of $dw_1$ for the derivative $\\frac{d \\mathcal{L}}{dw_1}$,\n",
    "\n",
    "```\n",
    "# Initialize variables to accumulate sums to compute average\n",
    "J = 0, dw_1 = 0, dw_2 = 0, db = 0\n",
    "\n",
    "# Iterate each example\n",
    "for i = 1 to n\n",
    "  \n",
    "  # Forward propagation to compute loss\n",
    "  z_i = w x_i + b\n",
    "  a_i = sigma(z_i)\n",
    "  J += -(y_i log(a_i) + (1 - y_i)log(1 - a_i))\n",
    "  \n",
    "  # Backpropagation to compute derivative\n",
    "  dz_i = a_i - y_i\n",
    "  dw_1 += x_1_i dz_i\n",
    "  dw_2 += x_2_i dz_i\n",
    "  db += dz_i\n",
    "  \n",
    "# Compute average\n",
    "J /= n, dw_1 /= n, dw_2 /= n, db /= n \n",
    "\n",
    "# Gradient descent\n",
    "w_1 = w_1 - alpha dw_1\n",
    "w_2 = w_2 - alpha dw_2\n",
    "b = b - alpha db\n",
    "```\n",
    "\n",
    "## Vectorization\n",
    "\n",
    "**Whenever possible, avoid explicit for-loops** in coding neural network\n",
    "\n",
    "## Resource\n",
    "\n",
    "- [Machine Learning by Stanford University | Coursera](https://www.coursera.org/learn/machine-learning)\n",
    "- [Deep Learning Specialization | Coursera](https://www.coursera.org/specializations/deep-learning)\n",
    "\n",
    "## Note\n",
    "\n",
    "$X = (p \\times n)$, $Y = (1 \\times n)$\n",
    "\n",
    "Logistic regression $\\hat{y} = \\sigma(w^T x + b)$\n",
    "\n",
    "Loss function is for single data error, $l(\\hat{y^{(i)}}, y^{(i)})$\n",
    "\n",
    "Cost function is for sum of loss functions for the entire dataset, $J(w, b)$\n",
    "\n",
    "https://www.coursera.org/learn/neural-networks-deep-learning/lecture/IgFnJ/vectorizing-logistic-regressions-gradient-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc57ea22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7119d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629dec0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1766738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ee672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-machine-learning",
   "language": "python",
   "name": "env-machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
