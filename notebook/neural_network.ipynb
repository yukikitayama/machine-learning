{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b087c50",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d8777e",
   "metadata": {},
   "source": [
    "## Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19834dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b81395",
   "metadata": {},
   "source": [
    "## Concept\n",
    "\n",
    "If network has $s_j$ units in layer $j$ and $s_{j + 1}$ units inlayer $j + 1$, then $\\Theta^{(j)}$ will be of dimension $s_{j + 1} \\times (s_{j} + 1)$. $+ 1$ because $s_{j + 1}$ has additional **bias unit**. $\\Theta^{(j)}$ is a matrix of **weights** controlling function mapping from layer $j$ to layer $j + 1$.\n",
    "\n",
    "When a neural network has **no hidden layers** and has only **one unit in output layer**,\n",
    "\n",
    "- If output layer is **linear activation**, it's **linear regression** because $y = I (\\Theta x) = \\Theta x$.\n",
    "- If output layer is **sigmoid activation**, it's **logistic regression** because $y = \\sigma(\\Theta x)$ where $\\sigma = \\frac{1}{1 + e^{(-\\Theta x)}}$.\n",
    "\n",
    "## Cost Function\n",
    "\n",
    "In **multi-class classification** where $n$ is the number of data, $L$ is the number of layers in neural network including input and output layers, $s_{l}$ is the number of units (not including bias unit) in layer $l$, $K$ is the number of classes, $\\Theta$ is the weight matrices, $h_{\\Theta}(x)$ is the output of neural network and $\\in \\mathbb{R}^K$, $(h_{\\Theta}(x))_i$ is $i^{th}$ output, and $J(\\Theta)$ is the cost.\n",
    "\n",
    "$$\n",
    "J(\\Theta) = - \\frac{1}{n} \\left[ \\sum_{i = 1}^{n} \\sum_{k = 1}^{K} y_{k}^{(i)} \\log (h_{\\Theta}(x^{(i)}))_{k} + (1 - y_{k}^{(i)}) \\log (1 - (h_{\\Theta}(x^{(i)}))_{k}) \\right] + \\frac{\\lambda}{2n} \\sum_{l = 1}^{L} \\sum_{i = 1}^{s_{l}} \\sum_{j = 1}^{s_{l + 1}} (\\Theta_{ji}^{(l)})^2\n",
    "$$\n",
    "\n",
    "This math takes the form of,\n",
    "\n",
    "$$\n",
    "\\text{Regularized cost} = \\text{Cost} + \\lambda \\times \\text{Regularization}\n",
    "$$\n",
    "\n",
    "The first $\\sum_{i = 1}^{n} \\sum_{k = 1}^{K} y_{k}^{(i)}$ part says that we get the **log-likelihood** by each class and sum up all the $n$ items and divide it by $n$ to get the average cost.\n",
    "\n",
    "The second $\\sum_{l = 1}^{L} \\sum_{i = 1}^{s_{l}} \\sum_{j = 1}^{s_{l + 1}}$ says that we get all the weight parameters in the neural network to regularize them.\n",
    "\n",
    "## Backpropagation\n",
    "\n",
    "**Backpropagation** is neural network terminology for minimizing the cost function. The goal is to compute,\n",
    "\n",
    "$$\n",
    "\\underset{\\Theta}{\\min} J(\\Theta)\n",
    "$$\n",
    "\n",
    "It means that we want to minimize the cost function $J$ using an optimal set of parameters $\\Theta$.\n",
    "\n",
    "## Gradient Descent\n",
    "\n",
    "### Logistic Regression Gradient Descent\n",
    "\n",
    "$$\n",
    "z = w^T x + b\n",
    "$$\n",
    "$$\n",
    "\\hat{y} = a = \\sigma(z)\n",
    "$$\n",
    "$$\n",
    "\\mathcal{L}(a, y) = -(y \\log(a) + (1 - y) \\log(1 - a))\n",
    "$$\n",
    "\n",
    "When $p = 2$,\n",
    "\n",
    "Computation graph is,\n",
    "\n",
    "$x_1, w_1, x_2, w_2, b \\rightarrow z = w_1 x_1 + w_2 x_2 + b \\rightarrow \\hat{y} = a = \\sigma(z) \\rightarrow \\mathcal{L}(a, y)$ \n",
    "\n",
    "By changing $w_1, w_2, b$, we want to reduce $\\mathcal{L}(a, y)$\n",
    "\n",
    "The loss function is,\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(a, y) = -(y \\log(a) + (1 - y) \\log(1 - a))\n",
    "$$\n",
    "\n",
    "Derivative of loss function with respect to $a$ is, by derivative of log and chain rule,\n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{da} = -y \\frac{1}{a} - (1 - y) \\frac{1}{1 - a} (-1)\n",
    "$$\n",
    "$$\n",
    "= \\frac{-y}{a} + \\frac{1 - y}{1 - a}\n",
    "$$\n",
    "$$\n",
    "= \\frac{-y(1 - a)}{a(1 - a)} + \\frac{(1 - y)a}{(1 - a)a}\n",
    "$$\n",
    "$$\n",
    "= \\frac{-y + ay + a - ay}{a(1 - a)}\n",
    "$$\n",
    "\n",
    "So we have,\n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{da} = \\frac{a - y}{a(1 - a)}\n",
    "$$\n",
    "\n",
    "Next, derivative of $a$ with respect to $z$, because $a = \\sigma(z)$,\n",
    "\n",
    "$$\n",
    "\\frac{da}{dz} = \\frac{d}{dz} \\sigma(z)\n",
    "$$\n",
    "\n",
    "Because derivative of sigmoid function is $\\frac{d}{dz} \\sigma(z) = \\sigma(z)(1 - \\sigma(z)$ and $a = \\sigma(z)$,\n",
    "\n",
    "$$\n",
    "\\frac{da}{dz} = a (1 - a)\n",
    "$$\n",
    "\n",
    "Finally, derivative of loss function with respect to $z$ is, by chain rule,\n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{dz} = \\frac{d \\mathcal{L}}{da} \\frac{da}{dz}\n",
    "$$\n",
    "$$\n",
    "= \\frac{a - y}{a(1 - a)} a (1 - a)\n",
    "$$\n",
    "\n",
    "So we have,\n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{dz} = a - y \n",
    "$$\n",
    "\n",
    "Now, we get derivative with respect to parameters, $\\frac{d \\mathcal{L}}{d w_1}$, $\\frac{d \\mathcal{L}}{d w_2}$, and $\\frac{d \\mathcal{L}}{db}$. By chain rule,\n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{d w_1} = \\frac{d \\mathcal{L}}{da} \\frac{da}{dz} \\frac{dz}{dw_1}\n",
    "$$\n",
    "\n",
    "Because $z = w_1 x_1 + w_2 x_2 + b$, derivative of $z$ with respect to $w_1$ is,\n",
    "\n",
    "$$\n",
    "\\frac{dz}{dw_1} = x_1\n",
    "$$\n",
    "\n",
    "Likewise,\n",
    "\n",
    "$$\n",
    "\\frac{dz}{dw_2} = x_2\n",
    "$$\n",
    "$$\n",
    "\\frac{dz}{db} = 1\n",
    "$$\n",
    "\n",
    "So finally derivative of loss function is each parameter is,\n",
    "\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{dw_1} = \\frac{a - y}{a(1 - a)} a (1 - a) x_1 = (a - y) x_1\n",
    "$$\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{dw_2} = \\frac{a - y}{a(1 - a)} a (1 - a) x_2 = (a - y) x_2\n",
    "$$\n",
    "$$\n",
    "\\frac{d \\mathcal{L}}{db} = \\frac{a - y}{a(1 - a)} a (1 - a) 1 = (a - y)\n",
    "$$\n",
    "\n",
    "Because we got the gradient with respect to parameters, finally we can do gradient descent by\n",
    "\n",
    "$$\n",
    "w_1 = w_1 - \\alpha \\frac{d \\mathcal{L}}{d w_1} = w_1 - \\alpha (a - y) x_1\n",
    "$$\n",
    "$$\n",
    "w_2 = w_2 - \\alpha \\frac{d \\mathcal{L}}{d w_2} = w_2 - \\alpha (a - y) x_2\n",
    "$$\n",
    "$$\n",
    "b = b - \\alpha \\frac{d \\mathcal{L}}{d b} = b - \\alpha (a - y)\n",
    "$$\n",
    "\n",
    "### Pseudocode for Gradient Descent in Neural Network\n",
    "\n",
    "When neural network architecture uses logistic regression, $p = 2$, $n$ is the number of data, and use the simplified expression of $dw_1$ for the derivative $\\frac{d \\mathcal{L}}{dw_1}$,\n",
    "\n",
    "```\n",
    "# Initialize variables to accumulate sums to compute average\n",
    "J = 0, dw_1 = 0, dw_2 = 0, db = 0\n",
    "\n",
    "# Iterate each example\n",
    "for i = 1 to n\n",
    "  \n",
    "  # Forward propagation to compute loss\n",
    "  z_i = w x_i + b\n",
    "  a_i = sigma(z_i)\n",
    "  J += -(y_i log(a_i) + (1 - y_i)log(1 - a_i))\n",
    "  \n",
    "  # Backpropagation to compute derivative\n",
    "  dz_i = a_i - y_i\n",
    "  dw_1 += x_1_i dz_i\n",
    "  dw_2 += x_2_i dz_i\n",
    "  db += dz_i\n",
    "  \n",
    "# Compute average\n",
    "J /= n, dw_1 /= n, dw_2 /= n, db /= n \n",
    "\n",
    "# Gradient descent\n",
    "w_1 = w_1 - alpha dw_1\n",
    "w_2 = w_2 - alpha dw_2\n",
    "b = b - alpha db\n",
    "```\n",
    "\n",
    "## Vectorization\n",
    "\n",
    "**Whenever possible, avoid explicit for-loops** in coding neural network\n",
    "\n",
    "2 layers neural network representation\n",
    "\n",
    "## Neural Network Representation\n",
    "\n",
    "**Input layer** doesn't count for layers in neural network. For example, logistic regression in neural network representation can be said to be 1 layer neural network, becuase the 1 layer is for the output layer. 1 hidden layer neural network is 2 layers neural network; 1 layer for the hidden layer, and 1 layer for the output layer.\n",
    "\n",
    "$l$ is the number of layers\n",
    "\n",
    "$n^{[l]}$ is the number of units (nodes) in layer $l$. Layer 0 is the inpute layer, so $n^{[0]}$ is the number of features.\n",
    "\n",
    "$a^{[l]}$ is the number of activations in layer $l$. $a^{[0]}$ is the input, so $x = a^{[0]}$. $a^{[L]}$ is the output.\n",
    "\n",
    "$w^{[l]}$ and $b^{[l]}$ are the weights for $z^{[l]}$\n",
    "\n",
    "Forward propagation is,\n",
    "\n",
    "$$\n",
    "Z^{[l]} = W^{[l]} A^{[l - 1]} + b^{[l]}\n",
    "$$\n",
    "$$\n",
    "A^{[l]} = g^{[l]}(Z^{[l]})\n",
    "$$\n",
    "\n",
    "The above is valid for the input layer too, because $X = A^{[0]}$.\n",
    "\n",
    "```\n",
    "A = X\n",
    "\n",
    "for i from 1 to L\n",
    "\n",
    "    Z_l = W_l A_(l - 1) + b_l\n",
    "    A_l = g_l(Z_l)\n",
    "```\n",
    "\n",
    "Dimension of weights\n",
    "\n",
    "$$\n",
    "W^{[l]}: (n^{[l]} \\times n^{[l - 1]})\n",
    "$$\n",
    "\n",
    "For example, from 2 features in the input layer to 3 units in the 1st hidden layer, as a single exmple, $n^{[0]} = 2$, $n^{[1]} = 3$\n",
    "\n",
    "$$\n",
    "z^{[1]} = w^{[1]} x + b^{[1]}\n",
    "$$\n",
    "$$\n",
    "(3 \\times 1) = (3 \\times 2) (2 \\times 1) + (2 \\times 1)\n",
    "$$\n",
    "\n",
    "**Bias** is always 1 column, so entire example vectorized implementation, **broadcasting** happens to bias. For example, $m$ is the number of examples (data)\n",
    "\n",
    "$$\n",
    "Z^{[l]} = W^{[l]} A^{[l - 1]} + b^{[l]}\n",
    "$$\n",
    "$$\n",
    "(n^{[l]} \\times m) = (n^{[l]} \\times n^{[l - 1]}) (n^{[l - 1]} \\times m) + (n^{[l]} \\times 1)\n",
    "$$\n",
    "\n",
    "In linear algebra, you cannot do element-wise addtion between $(n^{[l]} \\times m)$ and $(n^{[l]} \\times 1)$. So the bias column is applied to each column in $W A$. It is **broadcasting**. To understand broadcasting, for example, if we have $(2 \\times 2)$ $W$ and $(2 \\times 2)$ $X$ and $(2 \\times 1)$ $b$,\n",
    "\n",
    "$$\n",
    "W = \n",
    "\\begin{bmatrix}\n",
    "a & b\\\\\n",
    "c & d\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "e & f\\\\\n",
    "g & h\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "b = \n",
    "\\begin{bmatrix}\n",
    "i\\\\\n",
    "j\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "W X + b =\n",
    "\\begin{bmatrix}\n",
    "(ae + bg) + i & (af + bh) + i\\\\\n",
    "(ce + dg) + j & (cf + dh) + j\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Notice that $i$ and $j$ are repeated in each column.\n",
    "\n",
    "## Activation Function\n",
    "\n",
    "tanh\n",
    "\n",
    "relu\n",
    "\n",
    "leaky relu, g(z) = max(0.01z, z)\n",
    "\n",
    "why we need to use non-linear activation. Composition of 2 linear function is a linear function. If the data has a non-linearity, only linear activation neural network cannot express the relationship.\n",
    "\n",
    "Derivative of activation function\n",
    "\n",
    "Sigmoid function, $g'(z) = a (1 - a)$\n",
    "\n",
    "Hypobolic tangent function, $1 - (tanh(z))^2$, $g'(z) = 1 - a^2$\n",
    "\n",
    "relu, $g'(z) = 0$ if z < 0, 1 if z > 0, undefined if z = 0\n",
    "\n",
    "Leaky relu, g'(z) = 0.01 if z < 0, 1 if z > 0\n",
    "\n",
    "## Backpropagation for neural network with hidden layer\n",
    "\n",
    "https://www.coursera.org/learn/neural-networks-deep-learning/lecture/6dDj7/backpropagation-intuition-optional\n",
    "\n",
    "## Random weights initialization\n",
    "\n",
    "## Propagation\n",
    "\n",
    "Forward propagation for layer $l$\n",
    "\n",
    "Input $a^{[l - 1]}$. Output $a^{[l]}$ to compute final output, and output cache $z^{[l]}$ for backpropagation.\n",
    "\n",
    "$$\n",
    "Z^{[l]} = W^{[l]} A^{[l - 1]} + b^{[l]}\n",
    "$$\n",
    "$$\n",
    "A^{[l]} = g^{[l]}(Z^{[l]})\n",
    "$$\n",
    "\n",
    "Backpropagation for layer $l$\n",
    "\n",
    "Input $da^{l}$. Output $da^{[l - 1]}$ to compute $dz^{[l]}$, and output $dW^{[l]}$ and $db^{[l]}$ for gradient descent. Below $*$ is element-wise multiplication. $\\text{np}$ is numpy. $m$ is the number of data.\n",
    "\n",
    "$$\n",
    "dZ^{[l]} = dA^{[l]} * g^{[l]}(Z^{[l]})\n",
    "$$\n",
    "\n",
    "Or\n",
    "\n",
    "$$\n",
    "dZ^{[l]} = dA^{[l]} * g'(Z^{[l]})\n",
    "$$\n",
    "\n",
    "$$\n",
    "dW^{[l]} = \\frac{d \\mathcal{L}}{dW^{[l]}} = \\frac{1}{m} dZ^{[l]} A^{[l - 1]T}\n",
    "$$\n",
    "$$\n",
    "db^{[l]} = \\frac{d \\mathcal{L}}{db^{[l]}} = \\frac{1}{m} \\sum_{i = 1}^{m} dZ^{[l](i)} = \\frac{1}{m} \\text{np.sum}(dZ^{[l]}, \\text{axis=1, keepdim=True})\n",
    "$$\n",
    "$$\n",
    "dA^{[l - 1]} = \\frac{d \\mathcal{L}}{dA^{[l - 1]}} = W^{[l]T} dZ^{[l]}\n",
    "$$\n",
    "\n",
    "Proof???\n",
    "\n",
    "## Resource\n",
    "\n",
    "- [Machine Learning by Stanford University | Coursera](https://www.coursera.org/learn/machine-learning)\n",
    "- [Deep Learning Specialization | Coursera](https://www.coursera.org/specializations/deep-learning)\n",
    "\n",
    "## Note\n",
    "\n",
    "$X = (p \\times n)$, $Y = (1 \\times n)$\n",
    "\n",
    "Logistic regression $\\hat{y} = \\sigma(w^T x + b)$\n",
    "\n",
    "Loss function is for single data error, $l(\\hat{y^{(i)}}, y^{(i)})$\n",
    "\n",
    "Cost function is for sum of loss functions for the entire dataset, $J(w, b)$\n",
    "\n",
    "https://github.com/HeroKillerEver/coursera-deep-learning/blob/master/Neural%20Networks%20and%20Deep%20Learning/Building%20your%20Deep%20Neural%20Network%20-%20Step%20by%20Step/Building%2Byour%2BDeep%2BNeural%2BNetwork%2B-%2BStep%2Bby%2BStep%2Bv8.ipynb\n",
    "\n",
    "https://github.com/HeroKillerEver/coursera-deep-learning/blob/master/Neural%20Networks%20and%20Deep%20Learning/Building%20your%20Deep%20Neural%20Network%20-%20Step%20by%20Step/testCases_v4.py\n",
    "\n",
    "https://github.com/HeroKillerEver/coursera-deep-learning/blob/master/Neural%20Networks%20and%20Deep%20Learning/Deep%20Neural%20Network%20Application-Image%20Classification/Deep%2BNeural%2BNetwork%2B-%2BApplication%2Bv8.ipynb\n",
    "\n",
    "https://github.com/HeroKillerEver/coursera-deep-learning/blob/master/Neural%20Networks%20and%20Deep%20Learning/Deep%20Neural%20Network%20Application-Image%20Classification/dnn_app_utils_v3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcfb4f5",
   "metadata": {},
   "source": [
    "## Coding Neural Network Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7119d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def initialize_parameters_with_zeros(dim):\n",
    "    w = np.zeros(shape=(dim, 1))\n",
    "    b = 0\n",
    "    return w, b\n",
    "\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    n is the number of data. p is the number of features\n",
    "\n",
    "    Argument:\n",
    "    w: (p x 1) weights\n",
    "    b: bias scalar\n",
    "    X: (p x n) input data\n",
    "    Y: (1 x n) output data\n",
    "    \n",
    "    Return:\n",
    "    cost: a scalar, negative log-likelihood\n",
    "    dw: gradient of the loss with respect to w, (p x 1), same shape as w\n",
    "    db: gradient of the loss with respect to b, (1 x 1), same shape as b\n",
    "    \"\"\"\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    # Forward propagation\n",
    "    # Compute activation function\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    # Compute cost function\n",
    "    cost = (- 1 / n) * np.sum(Y * np.log(A) + (1 - Y) * (np.log(1 - A)))\n",
    "    cost = np.squeeze(cost)\n",
    "    \n",
    "    # Backpropagation\n",
    "    dw = (1 / n) * np.dot(X, (A - Y).T)\n",
    "    db = (1 / n) * np.sum(A - Y)\n",
    "    grads = {\n",
    "        'dw': dw,\n",
    "        'db': db\n",
    "    }\n",
    "    \n",
    "    return grads, cost\n",
    "\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate):\n",
    "    \"\"\"\n",
    "    This function repeats gradient descent to update weights in neural network\n",
    "    Argumet:\n",
    "    w: (p x 1) Weights\n",
    "    b: scalar bias\n",
    "    X: (p x n) input data\n",
    "    Y: (1 x n) output data\n",
    "    num_iterations: Number of iterations to repeat gradient descent\n",
    "    learning_rate: Learning rate for gradient descent\n",
    "    \n",
    "    Return:\n",
    "    params: Python dictionary containing the final parameters weights and bias\n",
    "    grads: Python dictionary containing the final gradient of weights and bias with respect to cost function\n",
    "    costs: List of costs from iterations\n",
    "    \"\"\"\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        # Do forward propagation and backpropagation to compute gradients\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        \n",
    "        # Update weights and bias by using the gradients\n",
    "        w = w - learning_rate * grads['dw']\n",
    "        b = b - learning_rate * grads['db']\n",
    "        \n",
    "        # Record cost\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "    \n",
    "    params = {\n",
    "        'w': w,\n",
    "        'b': b\n",
    "    }\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "629dec0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=100,\n",
    "    n_features=2,\n",
    "    n_informative=2,\n",
    "    n_redundant=0,\n",
    "    n_classes=2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(X, columns=['x1', 'x2'])\n",
    "df['y'] = y\n",
    "\n",
    "sns.scatterplot(x='x1', y='x2', data=df, hue='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "633ee672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [0.65479702]\n",
      "Coefficients: [[2.48256096 0.4595847 ]]\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(f'Intercept: {model.intercept_}')\n",
    "print(f'Coefficients: {model.coef_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6822f2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 0.8821201934552619\n",
      "Coefficients: [[3.1280681 ]\n",
      " [0.64042661]]\n"
     ]
    }
   ],
   "source": [
    "w = np.array([\n",
    "    [0.01],\n",
    "    [0.01]\n",
    "])\n",
    "b = 0.5\n",
    "\n",
    "params, grads, cost = optimize(w, b, X.T, y.T, num_iterations=10000, learning_rate=0.01)\n",
    "\n",
    "print(f'Intercept: {params[\"b\"]}')\n",
    "print(f'Coefficients: {params[\"w\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "abb44f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1dd64f9fc10>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d84499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9582dc67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738159ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b374fb7",
   "metadata": {},
   "source": [
    "## Deep Neural Network Binary Classification\n",
    "\n",
    "All the hidden layers use **Relu activation**. ReLu is $max(0, Z)$ where $Z = W A + b$. It's binary classification because the output layer uses the sigmoid activation.\n",
    "\n",
    "Parameters (weights $W$ and bias $b$) are initialized with random numbers. $W$ are random small number, and $b$ are all zeros.\n",
    "\n",
    "Deep layers are,\n",
    "\n",
    "Linear ($W, A, b$) &rarr; Relu activation &rarr; Linear ($W, A, b$) &rarr; Relu &rarr; ... &rarr; Linear($W, A, b$) &rarr; Sigmoid activation\n",
    "\n",
    "It uses the following cost function, called **cross-entropy cost**, because of binary classification. $a^{[L]} = \\hat{y}$ because $a^{[L]}$ is the output of the sigmoid activation at the output layer.\n",
    "\n",
    "$$\n",
    "- \\frac{1}{m} \\sum_{i = 1}^{m} \\left[ y^{(i)} \\log (a^{[L](i)}) + (1 - y^{(i)}) \\log (1 - a^{[L](i)}) \\right]\n",
    "$$\n",
    "\n",
    "Initialize backpropagation with $\\frac{\\partial \\mathcal{L}}{\\partial A^{[L]}}$\n",
    "\n",
    "Derivative of cost function with respect to $A$ is,\n",
    "\n",
    "$$\n",
    "- \\frac{y}{a} + \\frac{1 - y}{1 - a} = \\frac{-y(1 - a) + (1 - y)a}{a(1 - a)} = \\frac{-y + ya + a - ay}{a(1 - a)} = \\frac{a - y}{a(1 - a)}\n",
    "$$\n",
    "\n",
    "Updating parameters is gradient descent.\n",
    "\n",
    "$$\n",
    "W^{[l]} = W^{[l]} - \\alpha dW^{[l]}\n",
    "$$\n",
    "$$\n",
    "b^{[l]} = b^{[l]} - \\alpha db^{[l]}\n",
    "$$\n",
    "\n",
    "where $dW^{[l]} = \\frac{\\partial \\mathcal{L}}{\\partial W^{[l]}}$ and $db^{[l]} = \\frac{\\partial \\mathcal{L}}{\\partial b^{[l]}}$\n",
    "\n",
    "Algorithm for neural network is,\n",
    "\n",
    "```\n",
    "1. Initialize parameters (weights and biases)\n",
    "2. Repeat the following until fully trained\n",
    "  i. Forward propagation to compute predicted Y\n",
    "  ii. Compute cost between actual Y and predicted Y\n",
    "  iii. Backward propagation to compute gradients\n",
    "  iv. Update parameters by gradient descent\n",
    "3. Predict by forward propagation with the updated parameters\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fde7bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    A = np.maximum(0, Z)\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    return dZ\n",
    "\n",
    "\n",
    "def sigmoid(Z):\n",
    "    A = 1 / (1 + np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache\n",
    "    s = 1 / (1 + np.exp(-Z))\n",
    "    dZ = dA * s * (1 - s)\n",
    "    return dZ\n",
    "\n",
    "\n",
    "def initialize_parameters(layer_dims, seed):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    layer_dims: List of integers representing dimenstions of each layer\n",
    "    Return:\n",
    "    parameters: Dictionary containing weight matrices for W (n_l, n_{l - 1}) and bias columns (n_l, 1)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)\n",
    "    # Start from 1 to avoid index out of bound\n",
    "    for l in range(1, L):\n",
    "        # Initialize weights with small numbers so multiply by 0.01\n",
    "        parameters[f'W{l}'] = 0.01 * np.random.randn(layer_dims[l], layer_dims[l - 1])\n",
    "        # Initialize bias with zero\n",
    "        parameters[f'b{l}'] = np.zeros((layer_dims[l], 1))\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def linear_forward(A, W, b):\n",
    "    Z = np.dot(W, A) + b\n",
    "    cache = (A, W, b)\n",
    "    return Z, cache\n",
    "\n",
    "\n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "\n",
    "    if activation == 'relu':\n",
    "        A, activation_cache = relu(Z)\n",
    "    elif activation == 'sigmoid':\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        \n",
    "    cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    caches = []\n",
    "    # A^0 = X\n",
    "    A = X\n",
    "    # // 2 because parameters are doubled by w and b\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    # Hidden layers\n",
    "    for l in range(1, L):\n",
    "        A, cache = linear_activation_forward(\n",
    "            A,\n",
    "            parameters[f'W{l}'],\n",
    "            parameters[f'b{l}'],\n",
    "            # All the hidden layers use ReLU in this example\n",
    "            activation='relu'\n",
    "        )\n",
    "        caches.append(cache)\n",
    "        \n",
    "    # Output layer\n",
    "    # AL = sigmoid(W^L A^{L - 1} + b^L) = \\hat{Y}\n",
    "    AL, cache = linear_activation_forward(\n",
    "        A,\n",
    "        parameters[f'W{L}'],\n",
    "        parameters[f'b{L}'],\n",
    "        # Use sigmoid activation because this example is binary classification\n",
    "        activation='sigmoid'\n",
    "    )\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return AL, caches\n",
    "\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    AL: Output of sigmoid activation, so equal to \\hat{y}\n",
    "    Y: (1, number of examples)\n",
    "    \"\"\"\n",
    "    m = Y.shape[1]\n",
    "    # Compute cross-entropy cost\n",
    "    # np.multiply is element-wise multiplication\n",
    "    cost = (-1 / m) * np.sum(np.multiply(Y, np.log(AL)) + np.multiply(1 - Y, np.log(1 - AL)))\n",
    "    # np.squeeze removes all the length 1 dimensions, so [[1]] goes to 1, shape is ()\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost\n",
    "\n",
    "\n",
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = (1 / m) * np.dot(dZ, A_prev.T)\n",
    "    db = (1 / m) * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == 'relu':\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "    elif activation == 'sigmoid':\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "    \n",
    "    dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "def backward_propagation(AL, Y, caches):\n",
    "    # Gradients\n",
    "    grads = {}\n",
    "    L = len(caches)\n",
    "    m = AL.shape[1]\n",
    "    # Make AL have the same shape as AL (Y hat)\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    # Derivative of cost function with respect to A (sigmoid activation at the output layer)\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    \n",
    "    current_cache = caches[-1]\n",
    "    grads[f'dA{L - 1}'], grads[f'dA{L}'], grads[f'db{L}'] = linear_activation_backward(\n",
    "        dAL,\n",
    "        current_cache,\n",
    "        'sigmoid'\n",
    "    )\n",
    "    \n",
    "    # e.g. for i in reversed(range(3)): (2, 1, 0), \n",
    "    # So it's (0, 1, 2) and then reverse it\n",
    "    for l in reversed(range(L - 1)):\n",
    "        current_cache = caches[l]\n",
    "        grads[f'dA{l}'], grads[f'dW{l + 1}'], grads[f'db{l + 1}'] = linear_activation_backward(\n",
    "            grads[f'dA{l + 1}'],\n",
    "            current_cache,\n",
    "            'relu'\n",
    "        )\n",
    "    \n",
    "    return grads\n",
    "\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    # // 2 because parameters are doubled by w and b\n",
    "    L = len(parameters) // 2\n",
    "    \n",
    "    for l in range(L):\n",
    "        # Gradient descent\n",
    "        parameters[f'W{l + 1}'] = parameters[f'W{l + 1}'] - learning_rate * grads[f'dW{l + 1}']\n",
    "        parameters[f'b{l + 1}'] = parameters[f'b{l + 1}'] - learning_rate * grads[f'db{l + 1}']\n",
    "        \n",
    "    return parameters\n",
    "\n",
    "\n",
    "def predict(X, y, parameters):\n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2\n",
    "    p = np.zeros((1, m))\n",
    "    \n",
    "    # Forward propagation to compute Y hat\n",
    "    # In prediction, we don't need caches\n",
    "    probas, _ = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Convert the predicted probability to binary prediction\n",
    "    for i in range(probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "            \n",
    "    print(f'Accuracy: {np.sum((p == y) / m)}')\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56deb6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When input has 100 features, and to make 4 layers neural network\n",
    "# Last element needs to be 1 because of binary classification\n",
    "layer_dims = [100, 20, 7, 5, 1]\n",
    "learning_rate = 0.001\n",
    "num_iterations = 1000\n",
    "np.random.seed(0)\n",
    "\n",
    "# X: (p by n)\n",
    "X = np.array([])\n",
    "# Y: (1 by n)\n",
    "Y = np.array([])\n",
    "\n",
    "# Initialize parameters\n",
    "parameters = initialize_parameters(layer_dims)\n",
    "\n",
    "# Store cost computed from each iteration\n",
    "costs = []\n",
    "\n",
    "# Keep training until num_iterations times\n",
    "for _ in range(num_iterations):\n",
    "    \n",
    "    # Forward propagation to compute Y hat\n",
    "    AL, caches = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Compute cost\n",
    "    cost = compute_cost(AL, Y)\n",
    "    \n",
    "    # Backward propagation to compute gradients\n",
    "    grads = backward_propagation(AL, Y, caches)\n",
    "    \n",
    "    # Update parameters by gradient descent\n",
    "    parameters = update_parameters(parameters, grads, learning_rate)\n",
    "    \n",
    "    # Save cost\n",
    "    costs.append(cost)\n",
    "\n",
    "# Visualize cost reduced over training iterations\n",
    "plt.plot(np.squeeze(costs))\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations')\n",
    "plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0ff66a",
   "metadata": {},
   "source": [
    "## Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6344112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward_test_case():\n",
    "    np.random.seed(1)\n",
    "    \"\"\"\n",
    "    X = np.array([[-1.02387576, 1.12397796],\n",
    " [-1.62328545, 0.64667545],\n",
    " [-1.74314104, -0.59664964]])\n",
    "    W = np.array([[ 0.74505627, 1.97611078, -1.24412333]])\n",
    "    b = np.array([[1]])\n",
    "    \"\"\"\n",
    "    A = np.random.randn(3,2)\n",
    "    W = np.random.randn(1,3)\n",
    "    b = np.random.randn(1,1)\n",
    "    \n",
    "    return A, W, b\n",
    "\n",
    "def linear_activation_forward_test_case():\n",
    "    \"\"\"\n",
    "    X = np.array([[-1.02387576, 1.12397796],\n",
    " [-1.62328545, 0.64667545],\n",
    " [-1.74314104, -0.59664964]])\n",
    "    W = np.array([[ 0.74505627, 1.97611078, -1.24412333]])\n",
    "    b = 5\n",
    "    \"\"\"\n",
    "    np.random.seed(2)\n",
    "    A_prev = np.random.randn(3,2)\n",
    "    W = np.random.randn(1,3)\n",
    "    b = np.random.randn(1,1)\n",
    "    return A_prev, W, b\n",
    "\n",
    "def L_model_forward_test_case():\n",
    "    \"\"\"\n",
    "    X = np.array([[-1.02387576, 1.12397796],\n",
    " [-1.62328545, 0.64667545],\n",
    " [-1.74314104, -0.59664964]])\n",
    "    parameters = {'W1': np.array([[ 1.62434536, -0.61175641, -0.52817175],\n",
    "        [-1.07296862,  0.86540763, -2.3015387 ]]),\n",
    " 'W2': np.array([[ 1.74481176, -0.7612069 ]]),\n",
    " 'b1': np.array([[ 0.],\n",
    "        [ 0.]]),\n",
    " 'b2': np.array([[ 0.]])}\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    X = np.random.randn(4,2)\n",
    "    W1 = np.random.randn(3,4)\n",
    "    b1 = np.random.randn(3,1)\n",
    "    W2 = np.random.randn(1,3)\n",
    "    b2 = np.random.randn(1,1)\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return X, parameters\n",
    "\n",
    "def compute_cost_test_case():\n",
    "    Y = np.asarray([[1, 1, 1]])\n",
    "    aL = np.array([[.8,.9,0.4]])\n",
    "    \n",
    "    return Y, aL\n",
    "\n",
    "def linear_backward_test_case():\n",
    "    \"\"\"\n",
    "    z, linear_cache = (np.array([[-0.8019545 ,  3.85763489]]), (np.array([[-1.02387576,  1.12397796],\n",
    "       [-1.62328545,  0.64667545],\n",
    "       [-1.74314104, -0.59664964]]), np.array([[ 0.74505627,  1.97611078, -1.24412333]]), np.array([[1]]))\n",
    "    \"\"\"\n",
    "    np.random.seed(1)\n",
    "    dZ = np.random.randn(1,2)\n",
    "    A = np.random.randn(3,2)\n",
    "    W = np.random.randn(1,3)\n",
    "    b = np.random.randn(1,1)\n",
    "    linear_cache = (A, W, b)\n",
    "    return dZ, linear_cache\n",
    "\n",
    "def linear_activation_backward_test_case():\n",
    "    \"\"\"\n",
    "    aL, linear_activation_cache = (np.array([[ 3.1980455 ,  7.85763489]]), ((np.array([[-1.02387576,  1.12397796], [-1.62328545,  0.64667545], [-1.74314104, -0.59664964]]), np.array([[ 0.74505627,  1.97611078, -1.24412333]]), 5), np.array([[ 3.1980455 ,  7.85763489]])))\n",
    "    \"\"\"\n",
    "    np.random.seed(2)\n",
    "    dA = np.random.randn(1,2)\n",
    "    A = np.random.randn(3,2)\n",
    "    W = np.random.randn(1,3)\n",
    "    b = np.random.randn(1,1)\n",
    "    Z = np.random.randn(1,2)\n",
    "    linear_cache = (A, W, b)\n",
    "    activation_cache = Z\n",
    "    linear_activation_cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    return dA, linear_activation_cache\n",
    "\n",
    "def L_model_backward_test_case():\n",
    "    \"\"\"\n",
    "    X = np.random.rand(3,2)\n",
    "    Y = np.array([[1, 1]])\n",
    "    parameters = {'W1': np.array([[ 1.78862847,  0.43650985,  0.09649747]]), 'b1': np.array([[ 0.]])}\n",
    "    aL, caches = (np.array([[ 0.60298372,  0.87182628]]), [((np.array([[ 0.20445225,  0.87811744],\n",
    "           [ 0.02738759,  0.67046751],\n",
    "           [ 0.4173048 ,  0.55868983]]),\n",
    "    np.array([[ 1.78862847,  0.43650985,  0.09649747]]),\n",
    "    np.array([[ 0.]])),\n",
    "   np.array([[ 0.41791293,  1.91720367]]))])\n",
    "   \"\"\"\n",
    "    np.random.seed(3)\n",
    "    AL = np.random.randn(1, 2)\n",
    "    Y = np.array([[1, 0]])\n",
    "\n",
    "    A1 = np.random.randn(4,2)\n",
    "    W1 = np.random.randn(3,4)\n",
    "    b1 = np.random.randn(3,1)\n",
    "    Z1 = np.random.randn(3,2)\n",
    "    linear_cache_activation_1 = ((A1, W1, b1), Z1)\n",
    "\n",
    "    A2 = np.random.randn(3,2)\n",
    "    W2 = np.random.randn(1,3)\n",
    "    b2 = np.random.randn(1,1)\n",
    "    Z2 = np.random.randn(1,2)\n",
    "    linear_cache_activation_2 = ((A2, W2, b2), Z2)\n",
    "\n",
    "    caches = (linear_cache_activation_1, linear_cache_activation_2)\n",
    "\n",
    "    return AL, Y, caches\n",
    "\n",
    "def update_parameters_test_case():\n",
    "    \"\"\"\n",
    "    parameters = {'W1': np.array([[ 1.78862847,  0.43650985,  0.09649747],\n",
    "        [-1.8634927 , -0.2773882 , -0.35475898],\n",
    "        [-0.08274148, -0.62700068, -0.04381817],\n",
    "        [-0.47721803, -1.31386475,  0.88462238]]),\n",
    " 'W2': np.array([[ 0.88131804,  1.70957306,  0.05003364, -0.40467741],\n",
    "        [-0.54535995, -1.54647732,  0.98236743, -1.10106763],\n",
    "        [-1.18504653, -0.2056499 ,  1.48614836,  0.23671627]]),\n",
    " 'W3': np.array([[-1.02378514, -0.7129932 ,  0.62524497],\n",
    "        [-0.16051336, -0.76883635, -0.23003072]]),\n",
    " 'b1': np.array([[ 0.],\n",
    "        [ 0.],\n",
    "        [ 0.],\n",
    "        [ 0.]]),\n",
    " 'b2': np.array([[ 0.],\n",
    "        [ 0.],\n",
    "        [ 0.]]),\n",
    " 'b3': np.array([[ 0.],\n",
    "        [ 0.]])}\n",
    "    grads = {'dW1': np.array([[ 0.63070583,  0.66482653,  0.18308507],\n",
    "        [ 0.        ,  0.        ,  0.        ],\n",
    "        [ 0.        ,  0.        ,  0.        ],\n",
    "        [ 0.        ,  0.        ,  0.        ]]),\n",
    " 'dW2': np.array([[ 1.62934255,  0.        ,  0.        ,  0.        ],\n",
    "        [ 0.        ,  0.        ,  0.        ,  0.        ],\n",
    "        [ 0.        ,  0.        ,  0.        ,  0.        ]]),\n",
    " 'dW3': np.array([[-1.40260776,  0.        ,  0.        ]]),\n",
    " 'da1': np.array([[ 0.70760786,  0.65063504],\n",
    "        [ 0.17268975,  0.15878569],\n",
    "        [ 0.03817582,  0.03510211]]),\n",
    " 'da2': np.array([[ 0.39561478,  0.36376198],\n",
    "        [ 0.7674101 ,  0.70562233],\n",
    "        [ 0.0224596 ,  0.02065127],\n",
    "        [-0.18165561, -0.16702967]]),\n",
    " 'da3': np.array([[ 0.44888991,  0.41274769],\n",
    "        [ 0.31261975,  0.28744927],\n",
    "        [-0.27414557, -0.25207283]]),\n",
    " 'db1': 0.75937676204411464,\n",
    " 'db2': 0.86163759922811056,\n",
    " 'db3': -0.84161956022334572}\n",
    "    \"\"\"\n",
    "    np.random.seed(2)\n",
    "    W1 = np.random.randn(3,4)\n",
    "    b1 = np.random.randn(3,1)\n",
    "    W2 = np.random.randn(1,3)\n",
    "    b2 = np.random.randn(1,1)\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    np.random.seed(3)\n",
    "    dW1 = np.random.randn(3,4)\n",
    "    db1 = np.random.randn(3,1)\n",
    "    dW2 = np.random.randn(1,3)\n",
    "    db2 = np.random.randn(1,1)\n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return parameters, grads\n",
    "\n",
    "\n",
    "def L_model_forward_test_case_2hidden():\n",
    "    np.random.seed(6)\n",
    "    X = np.random.randn(5,4)\n",
    "    W1 = np.random.randn(4,5)\n",
    "    b1 = np.random.randn(4,1)\n",
    "    W2 = np.random.randn(3,4)\n",
    "    b2 = np.random.randn(3,1)\n",
    "    W3 = np.random.randn(1,3)\n",
    "    b3 = np.random.randn(1,1)\n",
    "  \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return X, parameters\n",
    "\n",
    "def print_grads(grads):\n",
    "    print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
    "    print (\"db1 = \"+ str(grads[\"db1\"]))\n",
    "    print (\"dA1 = \"+ str(grads[\"dA1\"]))     \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-machine-learning",
   "language": "python",
   "name": "env-machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
