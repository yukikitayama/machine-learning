{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6958faf",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dcc3ed",
   "metadata": {},
   "source": [
    "- Start with some $\\theta$\n",
    "- Keep changing $\\theta$ to reduce cost function $J(\\theta)$\n",
    "- Repeat until it ends up at a minimum\n",
    "\n",
    "Gradient descent algorithm\n",
    "\n",
    "$$\n",
    "\\theta_j = \\theta_j - \\alpha \\frac{\\partial}{\\partial \\theta_j} J(\\theta)\n",
    "$$\n",
    "\n",
    "$j$ is index for $p$ features. Repeat it until convergence. For each parameter, take derivative of cost function with respect to each parameter. Simultaneously update all the j $\\theta$'s\n",
    "\n",
    "Correct (Simultaneous update)\n",
    "\n",
    "temp0 = $\\theta_0 - \\alpha \\frac{\\partial}{\\partial \\theta_0} J(\\theta)$\n",
    "\n",
    "temp1 = $\\theta_1 - \\alpha \\frac{\\partial}{\\partial \\theta_1} J(\\theta)$\n",
    "\n",
    "$\\theta_0 = $ temp0\n",
    "\n",
    "$\\theta_1 = $ temp1\n",
    "\n",
    "Incorrect (Not simultaneous update)\n",
    "\n",
    "temp0 = $\\theta_0 - \\alpha \\frac{\\partial}{\\partial \\theta_0} J(\\theta)$\n",
    "\n",
    "$\\theta_0 = $ temp0\n",
    "\n",
    "temp1 = $\\theta_1 - \\alpha \\frac{\\partial}{\\partial \\theta_1} J(\\theta)$\n",
    "\n",
    "$\\theta_1 = $ temp1\n",
    "\n",
    "Gradient descent can converge to a local minimum even with the learning rate $\\alpha$ **fixed**. As it approaches a local minimum, gradient gets smaller, so gradient descent will take smaller steps. So no need to decrease $\\alpha$ over time.\n",
    "\n",
    "## Batch Gradient Descent\n",
    "\n",
    "Use **all n examples** in each iteration. I think it's **confusing** because batch sounds like a part of the data, but it actually uses all the data.\n",
    "\n",
    "In **linear regression** where the hypothesis function is $h_{\\theta}(x) = \\sum_{j = 0}^{p} \\theta_j x_j$ and the cost function is $J(\\theta) = \\frac{1}{2n} \\sum_{i = 1}^{n} (h_{\\theta}(x^{(i)}) - y^{(i)})^2$ by using the squared error, the derivative of the cost function with respect to parameters is $\\frac{\\partial}{\\partial \\theta} J(\\theta) = \\frac{1}{n} \\sum_{i = 1}^{n} (h_{\\theta}(x^{(i)}) - y^{(i)}) x_j^{(i)}$, the batch gradient descent is,\n",
    "\n",
    "$$\n",
    "\\theta_j = \\theta_j - \\alpha \\frac{1}{n} \\sum_{i = 1}^{n} (h_{\\theta}(x^{(i)}) - y^{(i)}) x_j^{(i)} \\quad \\text{for every } j = 0, ..., p\n",
    "$$\n",
    "\n",
    "$\\sum_{i = 1}^{n}$ tells us that, even for 1 iteration of parameter $\\theta$ update, we need to sum up all the data. It would be **slow** when $n = 300,000,000$ for example.\n",
    "\n",
    "\n",
    "## Stochastic Gradient Descent\n",
    "\n",
    "Use **1 example** in each iteration. Stochastic gradient descent defines a function for the single example like below,\n",
    "\n",
    "$$\n",
    "cost(\\theta, (x^{(i)}, y^{(i)})) = \\frac{1}{2} (h_{\\theta}(x^{(i)}) - y^{(i)})^2\n",
    "$$\n",
    "\n",
    "And define the overall cost function as,\n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{n} \\sum_{i = 1}^{n} cost(\\theta, (x^{(i)}, y^{(i)}))\n",
    "$$\n",
    "\n",
    "But in each iteration to update parameter $\\theta$ by gradient descent, it **doesn't sum up all the example**,\n",
    "\n",
    "$$\n",
    "\\theta_j = \\theta_j - \\alpha (h_{\\theta}(x^{(i)}) - y^{(i)}) x_j^{(i)} \\quad \\text{for every } j = 0, ..., p\n",
    "$$\n",
    "\n",
    "If we want parameter $\\theta$ to converge in stochastic gradient descent, we can slowly decrease learning rate $\\alpha$ over time (learning rate $\\alpha$ is typically held constant).\n",
    "\n",
    "$$\n",
    "\\alpha = \\frac{\\text{constant}_1}{\\text{Iteration number} + \\text{constant}_2}\n",
    "$$\n",
    "\n",
    "So **as iteration goes, the denominator gets larger, and learning rate $\\alpha$ gets smaller**. But maybe people won't do this, because you need to spend the extra time to tune these additional constant parameters such as $\\text{constant}_1$ and $\\text{constant}_2$ in the equation\n",
    "\n",
    "## Mini-Batch Gradient Descent\n",
    "\n",
    "Use **b examples** in each iteration. \n",
    "\n",
    "For example, $b = 10$. $n = 1000$. $p$ is the number of features.\n",
    "\n",
    "In 1st iteration,\n",
    "\n",
    "$$\n",
    "\\theta_j = \\theta_j - \\alpha \\frac{1}{10} \\sum_{k = i}^{i + 9} (h_{\\theta}(x^{(k)}) - y^{(k)}) x_j{(k)} \\quad (\\text{for every } j = 0, ..., p)\n",
    "$$\n",
    "\n",
    "It starts from $i = 1$. In the 1st iteration, 10 examples are used to update $\\theta_j$. In the 2nd iteration, it starts from $i = 11$ and ends at $i = 20$. Repeat it until $i = 1000$.\n",
    "\n",
    "People argue that, with a good implementation of **vectorization**, mini-batch gradient descent runs faster than stochastic gradient descent.\n",
    "\n",
    "## Feature Scaling\n",
    "\n",
    "If we make sure multiple features are on a **similar scales**, meaning having similar ranges of values, then gradient descent can **converge more quickly**.\n",
    "\n",
    "Contour of loss function (cost function) becomes a skewed elliptical shape. Gradient is likely to oscillate and take a long time to reach a global optimum, because gradient is **perpendicular** to contour.\n",
    "\n",
    "By scaling, contour becomes circle. Gradient descent is less likely to have oscillation.\n",
    "\n",
    "For example, get every feature into approximately a $-1 \\le x \\le 1$ range.\n",
    "\n",
    "**Mean normalization** is to replace $x$ with $x - \\mu$ to make features have approximately 0 mean (Do not apply to intercept $x_0 = 1$).\n",
    "\n",
    "## Reference\n",
    "\n",
    "- [Machine Learning by Stanford University | Coursera](https://www.coursera.org/learn/machine-learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1428d0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5623fbe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b84be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76b82e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-machine-learning",
   "language": "python",
   "name": "env-machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
