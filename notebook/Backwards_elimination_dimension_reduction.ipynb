{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension reduction by lasso and backwards elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a script to get fewer variables by lasso from high dimensional data, and then apply backwards elimination to build linear regression model with small p-value and small number of predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statistics\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data - train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df\n",
    "y_train_df\n",
    "X_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "alpha_lower = 0.01\n",
    "alpha_upper = 0.1\n",
    "\n",
    "# Setup the parameter grid\n",
    "alpha_space = np.arange(alpha_lower, alpha_upper, 0.01)\n",
    "param_grid = {'alpha':alpha_space}\n",
    "\n",
    "# Instantiate a lasso regression\n",
    "lasso = Lasso(normalize = True)\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "lasso_cv = GridSearchCV(lasso, param_grid, cv = k)\n",
    "\n",
    "# Fit it to data\n",
    "lasso_cv.fit(X_train_df.values, y_train_df.values)\n",
    "\n",
    "# Calculate training accuracy by RMSE\n",
    "y_pred = lasso_cv.predict(X_train_df.values)\n",
    "rmse = math.sqrt(statistics.mean((y_train_df.values - y_pred)**2))\n",
    "\n",
    "# Predictors\n",
    "best_alpha = lasso_cv.best_params_['alpha']\n",
    "lasso = Lasso(alpha = best_alpha, normalize = True)\n",
    "lasso.fit(X_train_df.values, y_train_df.values)\n",
    "lasso_coef = lasso.coef_\n",
    "p = sum(abs(lasso_coef) > 0)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned lasso regression hyperparameters: {}\".format(lasso_cv.best_params_))\n",
    "print(\"Best score: {0:.2f}\".format(lasso_cv.best_score_))\n",
    "print(\"RMSE: {0:.2f}\".format(rmse))\n",
    "print(\"Number of predictors: {}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation among predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = X_train_df.columns\n",
    "var = pd.Series(COLUMNS[abs(lasso_coef) > 0])\n",
    "coef = pd.Series(lasso_coef[abs(lasso_coef) > 0])\n",
    "lasso_result = pd.concat(objs = [var, coef],\n",
    "                         axis = 1,\n",
    "                         keys = ['Variable', 'Lasso_coefficient'])\n",
    "print(lasso_result.iloc[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = lasso_result['Variable'].tolist()\n",
    "corrmat = X_train_df[COLUMNS].corr()\n",
    "corrmat = corrmat.rename_axis(None).rename_axis(None, axis = 1)\n",
    "corrmat = corrmat.stack().reset_index()\n",
    "corrmat.columns = ['var_1', 'var_2', 'correlation']\n",
    "corrmat = corrmat[corrmat['correlation'] != 1]\n",
    "corrmat.sort_values(by = 'correlation', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso predictors p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = lasso_result['Variable'].tolist()\n",
    "X = X_train_df[COLUMNS].values\n",
    "X = sm.add_constant(X)\n",
    "y = y_train_df.values\n",
    "result = sm.OLS(y, X).fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backwards elimination with p-value control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial values\n",
    "COLUMNS = np.array(lasso_result['Variable'])\n",
    "X_train = X_train_df # we don't use validation set to check accuracy\n",
    "y_train = y_train_df\n",
    "p_max = 1.0\n",
    "i = 0 # counter\n",
    "\n",
    "# store validation result\n",
    "n = len(COLUMNS)\n",
    "p_list = np.zeros(n)\n",
    "max_pval_list = np.zeros(n)\n",
    "\n",
    "# threshold of p-value\n",
    "p_threshold = 0.00001\n",
    "\n",
    "while p_max > p_threshold:\n",
    "       \n",
    "    # run OLS regression\n",
    "    X = X_train[COLUMNS].values\n",
    "    X = sm.add_constant(X)\n",
    "    y = y_train.values\n",
    "    result = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # store number of predictors\n",
    "    p_list[i] = len(COLUMNS)\n",
    "    \n",
    "    # extract ols results\n",
    "    result_df = results_summary_to_dataframe(result)\n",
    "\n",
    "    # Adding Intercept label\n",
    "    COLUMNS_int = COLUMNS.copy()\n",
    "    COLUMNS_int = np.append('Intercept', COLUMNS_int)\n",
    "    result_df['predictors'] = COLUMNS_int\n",
    "    \n",
    "    # check max p-value\n",
    "    result_nonint = result_df.copy()\n",
    "    result_nonint = result_nonint.drop(0, axis = 0) # delete intercept row\n",
    "    max_pval_list[i] = max(result_nonint['pvals']) # store max p-value\n",
    "    p_max = max(result_nonint['pvals'])\n",
    "    \n",
    "    # delete one predictor\n",
    "    idx_del = result_nonint['pvals'].idxmax()\n",
    "    result_nonint = result_nonint.drop(idx_del, axis = 0)\n",
    "\n",
    "    # store list of predictors after drop one predictors\n",
    "    COLUMNS = np.array(result_nonint['predictors'])\n",
    "    \n",
    "    # counter plus one\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(p_max, decimals = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(max_pval_list, decimals = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(result_df, decimals = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(p_list, max_pval_list)\n",
    "_ = plt.xlabel('Number of predictors')\n",
    "_ = plt.ylabel('Max p-values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['predictors']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_final = np.array(result_df['predictors'].drop(0, axis = 0))\n",
    "COLUMNS_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train_df[COLUMNS_final].values\n",
    "X = sm.add_constant(X)\n",
    "y = y_train_df.values\n",
    "model = sm.OLS(y, X).fit()\n",
    "y_train_pred = model.predict(X)\n",
    "\n",
    "# Calculate accuracy\n",
    "rmse = math.sqrt(statistics.mean((y - y_train_pred)**2))\n",
    "print(\"RMSE of training: {:5.2f}\".format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test_df[COLUMNS_final].values\n",
    "X_test = sm.add_constant(X_test)\n",
    "test_pred = model.predict(X_test).round(1) # DREAM allows only 1 decimal point\n",
    "result = pd.concat([pd.Series(ID_test_df.values), pd.Series(test_pred)],\n",
    "                  axis = 1,\n",
    "                  keys = ['SampleID', 'GA'])\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
