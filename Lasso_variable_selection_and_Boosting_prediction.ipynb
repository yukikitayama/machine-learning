{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High dimensional data analysis by lasso and boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a script for selecting variables from high dimensional data by Lasso regression, train model based on the subset, and obtain prediction in test set by Stochastic Gradient Boosting (SGB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statistics\n",
    "import math\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor, GradientBoostingRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data - train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = # put some data\n",
    "y_train_df = # put some data\n",
    "X_test_df = # put some data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso hyperparameter tuning with grid search cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an alpha hyperparameter for a lasso model, we use grid search cross validation, then select variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "alpha_lower = 0.01\n",
    "alpha_upper = 0.1\n",
    "\n",
    "# Setup the parameter grid\n",
    "alpha_space = np.arange(alpha_lower, alpha_upper, 0.01)\n",
    "param_grid = {'alpha':alpha_space}\n",
    "\n",
    "# Instantiate a lasso regression\n",
    "lasso = Lasso(normalize = True)\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "lasso_cv = GridSearchCV(lasso, param_grid, cv = k)\n",
    "\n",
    "# Fit it to data\n",
    "lasso_cv.fit(X_train_df.values, y_train_df.values)\n",
    "\n",
    "# Calculate training accuracy by RMSE\n",
    "y_pred = lasso_cv.predict(X_train_df.values)\n",
    "rmse = math.sqrt(statistics.mean((y_train_df.values - y_pred)**2))\n",
    "\n",
    "# Predictors\n",
    "best_alpha = lasso_cv.best_params_['alpha']\n",
    "lasso = Lasso(alpha = best_alpha, normalize = True)\n",
    "lasso.fit(X_train_df.values, y_train_df.values)\n",
    "lasso_coef = lasso.coef_\n",
    "p = sum(abs(lasso_coef) > 0)\n",
    "\n",
    "# Print the tuned parameters and score\n",
    "print(\"Tuned lasso regression hyperparameters: {}\".format(lasso_cv.best_params_))\n",
    "print(\"Best score: {0:.2f}\".format(lasso_cv.best_score_))\n",
    "print(\"RMSE: {0:.2f}\".format(rmse))\n",
    "print(\"Number of predictors: {}\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use variables whose absolute value of coefficients is greater than zero to trian our prediction models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = X_train_df.columns\n",
    "var = pd.Series(COLUMNS[abs(lasso_coef) > 0])\n",
    "coef = pd.Series(lasso_coef[abs(lasso_coef) > 0])\n",
    "lasso_result = pd.concat(objs = [var, coef],\n",
    "                         axis = 1,\n",
    "                         keys = ['Variable', 'Lasso_coefficient'])\n",
    "print(lasso_result.iloc[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = np.array(lasso_result['Variable'])\n",
    "subset = X_train_df[COLUMNS]\n",
    "print(subset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train validation split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing several boosting methods with random hyperparameters which are cross validated later, and decide which one we use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "SIZE = 0.3\n",
    "\n",
    "X_train, X_vali, y_train, y_vali = train_test_split(subset, y_train_df, test_size = SIZE, random_state = SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb = AdaBoostRegressor(n_estimators = 100,\n",
    "                        random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb.fit(X_train, y_train)\n",
    "y_pred_train = adb.predict(X_train)\n",
    "y_pred_vali = adb.predict(X_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = MSE(y_train, y_pred_train)**(1/2)\n",
    "rmse_vali = MSE(y_vali, y_pred_vali)**(1/2)\n",
    "print(\"Training set RMSE: {:.2f}\".format(rmse_train))\n",
    "print(\"Validation set RMSE: {:.2f}\".format(rmse_vali))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt = GradientBoostingRegressor(n_estimators = 300,\n",
    "                                max_depth = 1,\n",
    "                                random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt.fit(X_train, y_train)\n",
    "y_pred_train = gbt.predict(X_train)\n",
    "y_pred_vali = gbt.predict(X_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = MSE(y_train, y_pred_train)**(1/2)\n",
    "rmse_vali = MSE(y_vali, y_pred_vali)**(1/2)\n",
    "print(\"Training set RMSE: {:.2f}\".format(rmse_train))\n",
    "print(\"Validation set RMSE: {:.2f}\".format(rmse_vali))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic gradient boosting (SGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgbt = GradientBoostingRegressor(max_depth = 1, # Defining decision stamp\n",
    "                                 subsample = 0.8, # Sample proportion of each tree\n",
    "                                 max_features = 0.2, # Maximum selected feature proportion to available features\n",
    "                                 n_estimators = 300, # Number of decision stamp\n",
    "                                 random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgbt.fit(X_train, y_train)\n",
    "y_pred_train = sgbt.predict(X_train)\n",
    "y_pred_vali = sgbt.predict(X_vali)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_train = MSE(y_train, y_pred_train)**(1/2)\n",
    "rmse_vali = MSE(y_vali, y_pred_vali)**(1/2)\n",
    "print(\"Training set RMSE: {:.2f}\".format(rmse_train))\n",
    "print(\"Validation set RMSE: {:.2f}\".format(rmse_vali))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGB hyperparameters tuning with grid search cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try SGB for prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgbt = GradientBoostingRegressor(random_state = SEED)\n",
    "print(sgbt.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters grids\n",
    "params_sgbt = {\n",
    "    'max_depth': [1],\n",
    "    'subsample': [0.2, 0.5, 0.8],\n",
    "    'max_features': [0.2, 0.5, 0.8],\n",
    "    'n_estimators': [100, 300, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_sgbt = GridSearchCV(estimator = sgbt,\n",
    "                         param_grid = params_sgbt,\n",
    "                         scoring = 'r2',\n",
    "                         cv = 10,\n",
    "                         n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_sgbt.fit(subset, y_train_df)\n",
    "grid_sgbt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparams = grid_sgbt.best_params_\n",
    "print(\"Best hyperparameters:\\n\", best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_CV_score = grid_sgbt.best_score_\n",
    "print(\"Best CV R-squared: {:.2f}\".format(best_CV_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_sgbt.best_estimator_\n",
    "\n",
    "vali_acc = best_model.score(X_vali, y_vali)\n",
    "\n",
    "print(\"Validation set R-squared of best model: {:.2f}\".format(vali_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_vali = best_model.predict(X_vali)\n",
    "rmse_train = MSE(y_train, y_pred_train)**(1/2)\n",
    "rmse_vali = MSE(y_vali, y_pred_vali)**(1/2)\n",
    "print(\"Training set RMSE: {:.2f}\".format(rmse_train))\n",
    "print(\"Validation set RMSE: {:.2f}\".format(rmse_vali))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check best hyperparameters obtained from cross validation\n",
    "best_hyperparams = grid_sgbt.best_params_\n",
    "print(\"Best hyperparameters:\\n\", best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input best hyperparameters\n",
    "sgbt = GradientBoostingRegressor(max_depth = 1, # Defining decision stamp\n",
    "                                 subsample = 0.5, # Sample proportion of each tree\n",
    "                                 max_features = 0.2, # Maximum selected feature proportion to available features\n",
    "                                 n_estimators = 300, # Number of decision stamp\n",
    "                                 random_state = SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgbt.fit(X_train_df, y_train_df)\n",
    "y_pred_test = sgbt.predict(X_test_df).round(1) # DREAM allows only 1 decimal point\n",
    "result = pd.concat([pd.Series(ID_test_df.values), pd.Series(y_pred_test)],\n",
    "                   axis = 1,\n",
    "                   keys = ['SampleID', 'GA'])\n",
    "result.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
