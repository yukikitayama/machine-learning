{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1192ef9",
   "metadata": {},
   "source": [
    "# Eigendecomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9f13a",
   "metadata": {},
   "source": [
    "## Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cf2b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da7a3d",
   "metadata": {},
   "source": [
    "## Application of eigendecomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade67671",
   "metadata": {},
   "source": [
    "- Principal component analysis\n",
    "- Regularization such as ridge regression\n",
    "- Linear discriminant analysis\n",
    "- Support vector machine\n",
    "\n",
    "So you need to understand eigendecomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae35c88",
   "metadata": {},
   "source": [
    "## Eigenvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306d587a",
   "metadata": {},
   "source": [
    "$$ A v = \\lambda v $$\n",
    "$$ A v - \\lambda v = 0 $$\n",
    "$$ (A - \\lambda I) v = 0 $$\n",
    "\n",
    "We cannot do $(A - \\lambda) v$, because $A$ is a matrix, but $\\lambda$ is a scalar.\n",
    "\n",
    "$(A - \\lambda I) v = 0$ means that a vector $v$ is in the **null space** of a matrix $A$ shifted by $-\\lambda I$, because it's producting 0 vector. $B v = 0$ means $v$ is in the **null space** of a matrix $B$.\n",
    "\n",
    "In eigendecomposition, we exclude a case where $v$ is a vector of all 0s. $v$ needs to have at least one element non-zero. So to produce 0 at the right side of the equation, $(A - \\lambda I)$ must be a **singular matrix** (**reduced rank matrix**). If $(A - \\lambda I)$ is a singular matrix, it means that a **determinant** of $(A - \\lambda I)$ is 0.\n",
    "\n",
    "$$ |A - \\lambda I| = 0 $$\n",
    "\n",
    "In $(A - \\lambda I) v = 0$, $0$ is a 0 vector, but in $|A - \\lambda I| = 0$, $0$ is a scalar 0. $|A - \\lambda I| = 0$ is called **characteristic equation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d5c23",
   "metadata": {},
   "source": [
    "## Eigenvalue of diagonal matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00aed3d",
   "metadata": {},
   "source": [
    "Eigenvalues of a diagonal matrix are diagonal elements of the diagonal matrix. For example,\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "1 & 0\\\\\n",
    "0 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "1 - \\lambda & 0\\\\\n",
    "0 & 2 - \\lambda\n",
    "\\end{vmatrix}\n",
    "= 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "(1 - \\lambda)(2 - \\lambda) = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lambda = 1, 2\n",
    "$$\n",
    "\n",
    "So we can imagine that, even if a diagonal matrix gets bigger, off-diagonal elements will disappear from **characteristic equations** and it gives us a bunch of $(d_i - \\lambda) = 0$, so we can directly use diagonal elements as eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b9eec88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagonal matrix\n",
      "[[ 1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  4  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  5  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  6  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  7  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  9  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 10]]\n",
      "\n",
      "Eigenvalues of diagonal matrix\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = np.diag(np.arange(1, 10 + 1))\n",
    "\n",
    "print('Diagonal matrix')\n",
    "print(A)\n",
    "print()\n",
    "\n",
    "eigen_values = np.linalg.eig(A)[0]\n",
    "print('Eigenvalues of diagonal matrix')\n",
    "print(eigen_values)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ad77a",
   "metadata": {},
   "source": [
    "## Eigenvalue of triangular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d8aefc",
   "metadata": {},
   "source": [
    "Eigenvalues of a triangular matrix has the same result as a diagonal matrix. That is, regardless of upper triangular matrix or lower triangular matrix, eigenvalues will be diagonal elements of the triangular matrix. For example in 2x2 upper triangular matrix,\n",
    "\n",
    "$$\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "1 & 2\\\\\n",
    "0 & 3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "1 - \\lambda & 2\\\\\n",
    "0 & 3 - \\lambda\n",
    "\\end{vmatrix}\n",
    "= 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "(1 - \\lambda)(3 - \\lambda) = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lambda = 1, 3\n",
    "$$\n",
    "\n",
    "Because when computing determinant and when making multiplication with diagonal elements, 0 at the either side of the diagonal cancels any number, so off-diagonal elements will disappear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dab12db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper triangular matrix\n",
      "[[-0.3  0.1  2.3 -1.8]\n",
      " [ 0.   1.1  0.4 -0.5]\n",
      " [ 0.   0.   1.  -1. ]\n",
      " [ 0.   0.   0.   0.5]]\n",
      "\n",
      "Eigenvalue\n",
      "[-0.3  1.1  1.   0.5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = np.triu(np.random.randn(4, 4))\n",
    "\n",
    "print('Upper triangular matrix')\n",
    "print(np.round(A, 1))\n",
    "print()\n",
    "\n",
    "eigen_values = np.linalg.eig(A)[0]\n",
    "\n",
    "print('Eigenvalue')\n",
    "print(np.round(eigen_values, 1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba6d4286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower triangular matrix\n",
      "[[ 1.5  0.   0.   0. ]\n",
      " [-1.2  0.2  0.   0. ]\n",
      " [-0.7  0.5  0.1  0. ]\n",
      " [-1.2  1.5  1.1 -0.9]]\n",
      "\n",
      "Eigenvalue\n",
      "[-0.9  0.1  0.2  1.5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = np.tril(np.random.randn(4, 4))\n",
    "\n",
    "print('Lower triangular matrix')\n",
    "print(np.round(A, 1))\n",
    "print()\n",
    "\n",
    "eigen_values = np.linalg.eig(A)[0]\n",
    "\n",
    "print('Eigenvalue')\n",
    "print(np.round(eigen_values, 1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60096d7",
   "metadata": {},
   "source": [
    "## Eigenvector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd656a4",
   "metadata": {},
   "source": [
    "Eigenvector is more important than eigenvector, but you need to compute eigenvalue before computing eigenvector\n",
    "\n",
    "1. Find all eigenvalues $\\lambda$\n",
    "2. For each $\\lambda$, find a vector $v$ which is in the **null space** of a shifted matrix by $\\lambda$, $(A - \\lambda I)$. That is $v \\in C(A - \\lambda I)$\n",
    "\n",
    "$v$ in the null space of $(A - \\lambda I)$ means that $(A - \\lambda I) v$ gives us a vector with all 0s in elements. In math,\n",
    "\n",
    "$$\n",
    "(A - \\lambda I) v = \\textbf{0}\n",
    "$$\n",
    "\n",
    "Typically, after finding those vectors, people normalize it, meaning the vector has a unit length.\n",
    "\n",
    "To double check the process to compute eigenvector, first find eigenvalues, and shift the original matrix by the eigenvalue, and find the **basis vector** (meaning normalized unit length vector) for the **null space** of the shifted matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a5ff02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix\n",
      "[[1 2]\n",
      " [2 1]]\n",
      "\n",
      "Eigenvector\n",
      "[[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n",
      "\n",
      "Eigenvalue\n",
      "[ 3. -1.]\n",
      "\n",
      "First eigenvalue: 3.0000000000000004 has the associated eigenvector\n",
      "in first column of the eigenvector matrix: [0.70710678 0.70710678]\n",
      "\n",
      "Second eigenvalue: -0.9999999999999996 has the associated eigenvector\n",
      "in second column of the eigenvector matrix: [-0.70710678  0.70710678]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1, 2],\n",
    "    [2, 1]\n",
    "])\n",
    "\n",
    "print('Matrix')\n",
    "print(A)\n",
    "print()\n",
    "\n",
    "evals, evecs = np.linalg.eig(A)\n",
    "\n",
    "print('Eigenvector')\n",
    "print(evecs)\n",
    "print()\n",
    "\n",
    "print('Eigenvalue')\n",
    "print(evals)\n",
    "print()\n",
    "\n",
    "print(f'First eigenvalue: {evals[0]} has the associated eigenvector')\n",
    "print(f'in first column of the eigenvector matrix: {evecs[:, 0]}')\n",
    "print()\n",
    "\n",
    "print(f'Second eigenvalue: {evals[1]} has the associated eigenvector')\n",
    "print(f'in second column of the eigenvector matrix: {evecs[:, 1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97afe48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From 134 udemy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-machine-learning",
   "language": "python",
   "name": "env-machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
