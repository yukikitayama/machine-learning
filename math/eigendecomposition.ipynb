{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1192ef9",
   "metadata": {},
   "source": [
    "# Eigendecomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e9f13a",
   "metadata": {},
   "source": [
    "## Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf2b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39da7a3d",
   "metadata": {},
   "source": [
    "## Application of eigendecomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade67671",
   "metadata": {},
   "source": [
    "- Principal component analysis\n",
    "- Regularization such as ridge regression\n",
    "- Linear discriminant analysis\n",
    "- Support vector machine\n",
    "\n",
    "So you need to understand eigendecomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae35c88",
   "metadata": {},
   "source": [
    "## Eigenvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306d587a",
   "metadata": {},
   "source": [
    "### How to compute eigenvalue\n",
    "\n",
    "$$ A v = \\lambda v $$\n",
    "$$ A v - \\lambda v = 0 $$\n",
    "$$ (A - \\lambda I) v = 0 $$\n",
    "\n",
    "We cannot do $(A - \\lambda) v$, because $A$ is a matrix, but $\\lambda$ is a scalar.\n",
    "\n",
    "$(A - \\lambda I) v = 0$ means that a vector $v$ is in the **null space** of a matrix $A$ shifted by $-\\lambda I$, because it's producting 0 vector. $B v = 0$ means $v$ is in the **null space** of a matrix $B$.\n",
    "\n",
    "In eigendecomposition, we exclude a case where $v$ is a vector of all 0s. $v$ needs to have at least one element non-zero. So to produce 0 at the right side of the equation, $(A - \\lambda I)$ must be a **singular matrix** (**reduced rank matrix**). If $(A - \\lambda I)$ is a singular matrix, it means that a **determinant** of $(A - \\lambda I)$ is 0.\n",
    "\n",
    "$$ |A - \\lambda I| = 0 $$\n",
    "\n",
    "In $(A - \\lambda I) v = 0$, $0$ is a 0 vector, but in $|A - \\lambda I| = 0$, $0$ is a scalar 0. $|A - \\lambda I| = 0$ is called **characteristic equation**.\n",
    "\n",
    "### How eigenvalue is related to the matrix\n",
    "\n",
    "If $A$ is a singular matrix (reduced-rank matrix, a matrix where one column can be a combination of other columns), at least one eigenvalue $\\lambda$ is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d5c23",
   "metadata": {},
   "source": [
    "## Eigenvalue of diagonal matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00aed3d",
   "metadata": {},
   "source": [
    "Eigenvalues of a diagonal matrix are diagonal elements of the diagonal matrix. For example,\n",
    "\n",
    "$$\n",
    "A = \n",
    "\\begin{bmatrix}\n",
    "1 & 0\\\\\n",
    "0 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "1 - \\lambda & 0\\\\\n",
    "0 & 2 - \\lambda\n",
    "\\end{vmatrix}\n",
    "= 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "(1 - \\lambda)(2 - \\lambda) = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lambda = 1, 2\n",
    "$$\n",
    "\n",
    "So we can imagine that, even if a diagonal matrix gets bigger, off-diagonal elements will disappear from **characteristic equations** and it gives us a bunch of $(d_i - \\lambda) = 0$, so we can directly use diagonal elements as eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b9eec88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagonal matrix\n",
      "[[ 1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  3  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  4  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  5  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  6  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  7  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  9  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 10]]\n",
      "\n",
      "Eigenvalues of diagonal matrix\n",
      "[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = np.diag(np.arange(1, 10 + 1))\n",
    "\n",
    "print('Diagonal matrix')\n",
    "print(A)\n",
    "print()\n",
    "\n",
    "eigen_values = np.linalg.eig(A)[0]\n",
    "print('Eigenvalues of diagonal matrix')\n",
    "print(eigen_values)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ad77a",
   "metadata": {},
   "source": [
    "## Eigenvalue of triangular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d8aefc",
   "metadata": {},
   "source": [
    "Eigenvalues of a triangular matrix has the same result as a diagonal matrix. That is, regardless of upper triangular matrix or lower triangular matrix, eigenvalues will be diagonal elements of the triangular matrix. For example in 2x2 upper triangular matrix,\n",
    "\n",
    "$$\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "1 & 2\\\\\n",
    "0 & 3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "1 - \\lambda & 2\\\\\n",
    "0 & 3 - \\lambda\n",
    "\\end{vmatrix}\n",
    "= 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "(1 - \\lambda)(3 - \\lambda) = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lambda = 1, 3\n",
    "$$\n",
    "\n",
    "Because when computing determinant and when making multiplication with diagonal elements, 0 at the either side of the diagonal cancels any number, so off-diagonal elements will disappear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dab12db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper triangular matrix\n",
      "[[-0.3  0.1  2.3 -1.8]\n",
      " [ 0.   1.1  0.4 -0.5]\n",
      " [ 0.   0.   1.  -1. ]\n",
      " [ 0.   0.   0.   0.5]]\n",
      "\n",
      "Eigenvalue\n",
      "[-0.3  1.1  1.   0.5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = np.triu(np.random.randn(4, 4))\n",
    "\n",
    "print('Upper triangular matrix')\n",
    "print(np.round(A, 1))\n",
    "print()\n",
    "\n",
    "eigen_values = np.linalg.eig(A)[0]\n",
    "\n",
    "print('Eigenvalue')\n",
    "print(np.round(eigen_values, 1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba6d4286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower triangular matrix\n",
      "[[ 1.5  0.   0.   0. ]\n",
      " [-1.2  0.2  0.   0. ]\n",
      " [-0.7  0.5  0.1  0. ]\n",
      " [-1.2  1.5  1.1 -0.9]]\n",
      "\n",
      "Eigenvalue\n",
      "[-0.9  0.1  0.2  1.5]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = np.tril(np.random.randn(4, 4))\n",
    "\n",
    "print('Lower triangular matrix')\n",
    "print(np.round(A, 1))\n",
    "print()\n",
    "\n",
    "eigen_values = np.linalg.eig(A)[0]\n",
    "\n",
    "print('Eigenvalue')\n",
    "print(np.round(eigen_values, 1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60096d7",
   "metadata": {},
   "source": [
    "## Eigenvector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd656a4",
   "metadata": {},
   "source": [
    "Eigenvector is more important than eigenvector, but you need to compute eigenvalue before computing eigenvector\n",
    "\n",
    "1. Find all eigenvalues $\\lambda$\n",
    "2. For each $\\lambda$, find a vector $v$ which is in the **null space** of a shifted matrix by $\\lambda$, $(A - \\lambda I)$. That is $v \\in C(A - \\lambda I)$\n",
    "\n",
    "$v$ in the null space of $(A - \\lambda I)$ means that $(A - \\lambda I) v$ gives us a vector with all 0s in elements. In math,\n",
    "\n",
    "$$\n",
    "(A - \\lambda I) v = \\textbf{0}\n",
    "$$\n",
    "\n",
    "Typically, after finding those vectors, people normalize it, meaning the vector has a unit length.\n",
    "\n",
    "To double check the process to compute eigenvector, first find eigenvalues, and shift the original matrix by the eigenvalue, and find the **basis vector** (meaning normalized unit length vector) for the **null space** of the shifted matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a5ff02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix\n",
      "[[1 2]\n",
      " [2 1]]\n",
      "\n",
      "Eigenvector\n",
      "[[ 0.70710678 -0.70710678]\n",
      " [ 0.70710678  0.70710678]]\n",
      "\n",
      "Eigenvalue\n",
      "[ 3. -1.]\n",
      "\n",
      "First eigenvalue: 3.0000000000000004 has the associated eigenvector\n",
      "in first column of the eigenvector matrix: [0.70710678 0.70710678]\n",
      "\n",
      "Second eigenvalue: -0.9999999999999996 has the associated eigenvector\n",
      "in second column of the eigenvector matrix: [-0.70710678  0.70710678]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1, 2],\n",
    "    [2, 1]\n",
    "])\n",
    "\n",
    "print('Matrix')\n",
    "print(A)\n",
    "print()\n",
    "\n",
    "evals, evecs = np.linalg.eig(A)\n",
    "\n",
    "print('Eigenvector')\n",
    "print(evecs)\n",
    "print()\n",
    "\n",
    "print('Eigenvalue')\n",
    "print(evals)\n",
    "print()\n",
    "\n",
    "print(f'First eigenvalue: {evals[0]} has the associated eigenvector')\n",
    "print(f'in first column of the eigenvector matrix: {evecs[:, 0]}')\n",
    "print()\n",
    "\n",
    "print(f'Second eigenvalue: {evals[1]} has the associated eigenvector')\n",
    "print(f'in second column of the eigenvector matrix: {evecs[:, 1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd2c6f5",
   "metadata": {},
   "source": [
    "## Diagonalization of a matrix with eigenvalues and eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da3376",
   "metadata": {},
   "source": [
    "**Diagonalization** in the context of eigendecomposition means to extract a special property of a given matrix in a form of a diagonal matrix by using eigenvalue and eigenvector.\n",
    "\n",
    "After decomposition, we have a set of eigen values and the according eigen vectors. For example in 3x3,\n",
    "\n",
    "$$\n",
    "A v_1 = \\lambda_1 v_1\n",
    "$$\n",
    "$$\n",
    "A v_2 = \\lambda_2 v_2\n",
    "$$\n",
    "$$\n",
    "A v_3 = \\lambda_3 v_3\n",
    "$$\n",
    "\n",
    "These can be written in matrix as below. Let $v_{1} = [v_{11}, v_{21}, v_{31}]$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "v_1 & v_2 & v_3\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\lambda_1 & 0 & 0\\\\\n",
    "0 & \\lambda_2 & 0\\\\\n",
    "0 & 0 & \\lambda_3\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "v_{11} & v_{12} & v_{13}\\\\\n",
    "v_{21} & v_{22} & v_{23}\\\\\n",
    "v_{31} & v_{32} & v_{33}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\lambda_1 & 0 & 0\\\\\n",
    "0 & \\lambda_2 & 0\\\\\n",
    "0 & 0 & \\lambda_3\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\lambda_1 v_{11} & \\lambda_2 v_{12} & \\lambda_3 v_{13}\\\\\n",
    "\\lambda_1 v_{21} & \\lambda_2 v_{22} & \\lambda_3 v_{23}\\\\\n",
    "\\lambda_1 v_{31} & \\lambda_2 v_{32} & \\lambda_3 v_{33}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "A matrix with eigenvectors must **left multiply** a diagonal matrix of eigenvalues because the below is wrong.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\lambda_1 & 0 & 0\\\\\n",
    "0 & \\lambda_2 & 0\\\\\n",
    "0 & 0 & \\lambda_3\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "v_{11} & v_{12} & v_{13}\\\\\n",
    "v_{21} & v_{22} & v_{23}\\\\\n",
    "v_{31} & v_{32} & v_{33}\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "\\lambda_1 v_{11} & \\lambda_1 v_{12} & \\lambda_1 v_{13}\\\\\n",
    "\\lambda_2 v_{21} & \\lambda_2 v_{22} & \\lambda_2 v_{23}\\\\\n",
    "\\lambda_3 v_{31} & \\lambda_3 v_{32} & \\lambda_3 v_{33}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "That means that first eigenvalue is multiplied with the first element of each eigenvector. But it's wrong, becasue eigenvalue and eigenvector is a pair. You cannot mix an eigenvalue with a different eigenvector.\n",
    "\n",
    "So a set of $A v_i = \\lambda v_i$ can be written as below by using $A$ is the given matrix, $V$ is a matrix with eigenvectors in each column, and $\\Lambda$ is a diagonal matrix of eigenvalues.\n",
    "\n",
    "$$\n",
    "A V = V \\Lambda\n",
    "$$\n",
    "\n",
    "By right multiplying the both sides by $V^{-1}$\n",
    "\n",
    "$$\n",
    "A V V^{-1} = V \\Lambda V^{-1}\n",
    "$$\n",
    "$$\n",
    "A I = V \\Lambda V^{-1}\n",
    "$$\n",
    "$$\n",
    "A = V \\Lambda V^{-1}\n",
    "$$\n",
    "\n",
    "That can be interpreted as a hidden insight of a given square matrix $A$ is a diagonal matrix $\\Lambda$ by passing through $V$ and $V^{-1}$. And it also suggests that the given square matrix $A$ can be reconstructed by a set of eigenvectors $V$ and $V^{-1}$, and a diagonal matrix of eigenvalues $\\Lambda$.\n",
    "\n",
    "Also, after diagonalization, matrix powers will be easy.\n",
    "\n",
    "$$\n",
    "A = V \\Lambda V^{-1}\n",
    "$$\n",
    "\n",
    "Suppose getting $A$ to the 3rd power\n",
    "\n",
    "$$\n",
    "A^3 = (V \\Lambda V^{-1}) (V \\Lambda V^{-1}) (V \\Lambda V^{-1})\n",
    "$$\n",
    "\n",
    "By regrouping the matrices\n",
    "\n",
    "$$\n",
    "A^3 = V \\Lambda (V^{-1} V) \\Lambda (V^{-1} V) \\Lambda V^{-1}\n",
    "$$\n",
    "\n",
    "Because $V^{-1} V = I$\n",
    "\n",
    "$$\n",
    "A^3 = V \\Lambda I \\Lambda I \\Lambda V^{-1}\n",
    "$$\n",
    "$$\n",
    "A^3 = V \\Lambda \\Lambda \\Lambda V^{-1}\n",
    "$$\n",
    "\n",
    "Because $\\Lambda$ is a diagonal matrix, so $D D = D^2$\n",
    "\n",
    "$$\n",
    "A^3 = V \\Lambda^3 V^{-1}\n",
    "$$\n",
    "\n",
    "We just first did eigendecomposition, and get the power, but it still works by first getting power and do eigendecomposition, because if we have $A x = \\lambda x$, $A^2$ is\n",
    "\n",
    "$$\n",
    "A^2 x = A A x\n",
    "$$\n",
    "\n",
    "Because $A x = \\lambda x$\n",
    "\n",
    "$$\n",
    "A^2 x = A A x = A \\lambda x\n",
    "$$\n",
    "\n",
    "We cannot change the order of matrix multiplication, but $\\lambda$ is a scalar, so we can move it, so move it front\n",
    "\n",
    "$$\n",
    "A^2 x = A A x = A \\lambda x = \\lambda A x\n",
    "$$\n",
    "\n",
    "Because $A x = \\lambda x$\n",
    "\n",
    "$$\n",
    "A^2 x = A A x = A \\lambda x = \\lambda A x = \\lambda \\lambda x\n",
    "$$\n",
    "\n",
    "Because $\\lambda$ is a scalar\n",
    "\n",
    "$$\n",
    "A^2 x = A A x = A \\lambda x = \\lambda A x = \\lambda \\lambda x = \\lambda^2 x\n",
    "$$\n",
    "$$\n",
    "A^2 x = \\lambda^2 x\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65b63d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABqCAYAAAAfgIIWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAALFElEQVR4nO3df2zV1RnH8c/h0t4Saqm/kOmEIrOGX4o4hygdKgyZioOgjjAUt6lL/MMMIUuYm2bOhfhrG9lwbstAJTgVRN0IUeYSHYJDw8yGKCq4DoUCogHbUaW0Z3+0TRjheWrvpedyy/uV9I/eJ+d8T789Pnz58vicEGMUACCNHoVeAAAcS0i6AJAQSRcAEiLpAkBCJF0ASIikCwAJkXQBdEshhD4hhFdDCA0hhGGFXk87ki6A7mqfpCskLSv0Qg5G0gXQLcUYm2KMHxZ6HYci6QI4KoUQMiGExhDC8MPEHgshPFyAZeWtZ6EXAACHE2NsDiFskjRE0ob2z0MIX5Y0SdJZIYR+kh4/zPBpMcYdaVbaOUWVdEMIL0o6R1K/GONnBV5O0QshPCfp1RjjHYd8/g1Jv5X0xRjjgYIsrhth3+blDbUm3YPdL+mBGOP2tu8vTrqiPBXN64UQQpWkGklR0lWFXU238YikGSGEcMjn10laQsLNX9u+PU/SVrFvc7FR0tD2b0IIkySdKenezzM4hLBS0gRJvw8h3NAVC+ysUCxdxkIId0i6TNI6SdUxxisLvKSiF0LoJWmHpEkxxr+1fXa8pDpJo2KM/yzk+rqDtn17llr37QT2beeEEK6UdG+McUgIISPpX5LuizE+XNiV5a5onnQlXS9pSdvXZSGEUwq8nqIXY2yU9KRa7227ayVtIuEeMddLekzSE5LGs287baOkM0MIJZK+K+kzSY8Wdkn5KYqkG0IYI2mApCdjjOslbZE0vbCr6jYekXR1CKGs7fvr2z5Dntr2bR9Jz8cYd0p6SezbzqpVa6I9V9JPJN0WY2wp6IryVBRJV9JMSatijLvbvn+s7TPkKcb4sqTdkiaHEAZJ+opa7y/yN1OtDwrt78aXiH3bKbH1/eebkh6StC7G+GJhV5S/o/6d7kHvHTOSGto+zkqqlDSCvwbnr+294wVqfe94Pu8d83fQvv16jHFt22fHSdopaTT79vMLISyUNEPS0Bjju4VeT76K4Ul3sqRmtZaNjGj7Gixptf7/XSRy96ik8ZJuEq8WjpTJkj5qT7iSFGOsl/QnsW87Jcb4nRhjaXdIuFJxJN2ZkhbFGLfGGHe0f0n6taRvhRCKqtb4aBRjrJW0VlJvtSYF5G+mpD8e5vMlYt8e04761wsA0J0Uw5MuAHQbJF0ASIikCwAJkXQBICH3X1Affme0+a9sd740xZ34pHX21L3r7D4q22vscdnBe91rNq+vNGONVfvNWGldiTtvU3+7MVTtdXMPbRbzuc16/Zvm/e2VaXLHPrdgjBmrfNde7ydVWTM2dfYL7jUXPjvejPXZbI/L7vX/B6K6MfYtfG/W7Jzub8uOM817e9mpI3KZstv5S8vSnO6tt2+f/vv57thMg/2cV/3gB2aseZG9h5ZVP+Vec/iKW81Y9oRGMza6f60778vvDTJjW6bdbt5bnnQBICGSLgAkRNIFgIRIugCQEEkXABIi6QJAQm7JmFcW1utEu9RCkvYfV2HGGvvaJVrZj51J11a612wpt2MVG0rNWMk+v/9E474yN54rr7ym8vQ97tg9Y+yysOM32T9P+Qd26dwz88a519xf02zGpk9Z5Y71LL99gh2clducXlnYO7/zy5qqb34tt4seI7xyxo727clXvW3G3pp/gRk76RG7um1s1t8kmbGfmrGbh6wxYwtWOftSUs/T9rlxC0+6AJAQSRcAEiLpAkBCJF0ASIikCwAJkXQBICGSLgAk5Nbpeu0ZvTpcSVr4/V+asWvXfM+MxWan29xevwVjdnfGjJXW27WrjX39DncHyrvmHDmvzZ1XzyhJFZfbtaa1V9i/t77/sH+WXZfbtb+SNGek3frx/tUTzVjZNv/3duDCtOf0dVSHW/vT0Was6sevHOnlFB2vrahXPy75+7b/83Yd+Icj7D3U4m8vlb7Zy4y9cNdIM1Z+j99K9uT59ry6xg7xpAsACZF0ASAhki4AJETSBYCESLoAkBBJFwASckvGvFN7vfaMkl8WtuXSRWZszK32uN7L1rnXfP9HF5qxvV+yxw1Y6bdoe3+CUxqSB+/0U6/NneSX1xw43v691Y2x/5wd2O8j95orpteYsYqx9n44Z9ob7ryvLx/mxlPzysJ23WLvsb4Pru2K5Rx1vNOmvbaikl/O6O3bTL19GnDwykwlnXT2LjM2dYbd2nFS+RZ33ppxc9y4hSddAEiIpAsACZF0ASAhki4AJETSBYCESLoAkJBbMra9xg67p/bK7xbmlYV9PO2/9pw3nuFfdLUdyuy317N1YgclYX5FSs6aF9llMN7pp5Lfdckrrxl47jYz1vCH09xrZht2mrFzptnlb9vnOvV6knoOdcNHFa8sLJw/3IzF1zZ0xXIK4pOqrBnzTpuW/C53bjmjs287dOeJZmj+nEvM2NK7x7vThh805LQcnnQBICGSLgAkRNIFgIRIugCQEEkXABIi6QJAQm7JWHawczDb2kp/ZucQSa9bmFcWtubs5e4lh714ixn77Di7VKXHQLtMTZKadnVNl7Fl1U+ZsbHZWe5Y7zC+jrouWXaO8uMfD+1nxurv62vGnl78c3feC56Y7V+4SHhlYZmhZ7ljmzf6B5EeTabOtg8ofWbeOHesd/ip1+XOK2fsaN8O3vxvMxZfHmTGvrrwr+6827ac51/YwJMuACRE0gWAhEi6AJAQSRcAEiLpAkBCJF0ASIikCwAJuXW6zesrzVhLuT9xdnfGjHmn9nrtGb06XElqHNpoxuInpWYsvNfbnbfEPqQ0L8NX3GrGMmM/dceWvmnXDnunn3pt7rx6Rkn6zw12TWNLT7s2eNRSvw73h1c840S7Rw1vMdXhdmThs3bLw/019inVkjRnpF3j65027bUV9erHJX/fXjx1vRlb/qtL3Xkbq92wiSddAEiIpAsACZF0ASAhki4AJETSBYCESLoAkJBbMtZYZZ/sWbHBLsGSpNJ6u5XiXudwWO/UXq89o+SXhd1+6bNmbN7Kye68LV9ocuO5yp5gl7jdPGSNO/aFu0aasakz7LHe6ademzvJL69ZuXGYPbDe3WZaPHuSGbtphTv0mNCjrMyMtXzqlxZ2hT6b7dj0KavcsfevnmjGKsba/Uq906a9tqKSX87o7dthM/wSysUDvFazt5kRnnQBICGSLgAkRNIFgIRIugCQEEkXABIi6QJAQm4tT2mdXcJRss8v32rsa5dpDFi5z4xtnWh3z+ro1F6vW5hXFjblEvt0Ykl6fsloN56r0f1rzdiCVRPcseX32Cc1TyrfYsaW3m13iOro9FOv65JXXvPWNr8LVN1FXXPacnfhlYVlKvu4Y5v3OCd65yi7tyXnsWXbvLKwN8zY9rl2nWlHp027Xe6ccsaO9u2NjTPM2Cv97XE86QJAQiRdAEiIpAsACZF0ASAhki4AJETSBYCESLoAkFCI0a63rVo8zwz22mS3m5OkA+X2vME5MDTahwirqcKvDyzZY/8Z0nS63aayfEPWnXf/qHoz9s7Vd9gFyR0Y9PjPzJvUI+P/rKc/ZNcXvj/O/nlCdYMZKynxT3Jt3GzXhP75mgfM2I2b7HpGSVpztt0ir0e/d3O6v1/rcY1fSH6MyJxitz18rm5BTvf2jF88YN7bU1f7+7buQvs/8LIP7eX0tEv7VT/Qv+Zc57Rpr61o3UV+S9K3v/0bM+btW550ASAhki4AJETSBYCESLoAkBBJFwASIukCQEJuyRgA4MjiSRcAEiLpAkBCJF0ASIikCwAJkXQBICGSLgAk9D/Kh9xLK4BGLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = np.random.randn(10, 10)\n",
    "A = A.T @ A\n",
    "\n",
    "# D: eigenvalue, V: eigenvector\n",
    "D, V = np.linalg.eig(A)\n",
    "\n",
    "# Visualize\n",
    "plt.subplot(141)\n",
    "plt.imshow(A)\n",
    "plt.title('A')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(142)\n",
    "plt.imshow(V)\n",
    "plt.title('V')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(143)\n",
    "plt.imshow(np.diag(D))\n",
    "plt.title('$\\Lambda$')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(144)\n",
    "plt.imshow(np.linalg.inv(V))\n",
    "plt.title('$V^{-1}$')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "575fd8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "[[0.903 0.968]\n",
      " [0.75  0.071]]\n",
      "\n",
      "A^3\n",
      "[[2.101 1.559]\n",
      " [1.209 0.759]]\n",
      "\n",
      "V Lambda^3 V^{-1}\n",
      "[[2.101 1.559]\n",
      " [1.209 0.759]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A = np.random.rand(2, 2)\n",
    "\n",
    "print('A')\n",
    "print(np.round(A, 3))\n",
    "print()\n",
    "\n",
    "# Matrix powers by function\n",
    "print('A^3')\n",
    "print(np.round(np.linalg.matrix_power(A, 3), 3))\n",
    "print()\n",
    "\n",
    "# Matrix powers by eigendecomposition and diagonalization\n",
    "# D: eigenvalue, V: eigenvector\n",
    "D, V = np.linalg.eig(A)\n",
    "D = np.diag(D)\n",
    "result = V @ D @ D @ D @ np.linalg.inv(V)\n",
    "\n",
    "print('V Lambda^3 V^{-1}')\n",
    "print(np.round(result, 3))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d98717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "[[ 120.  -68. -186.   66.]\n",
      " [ -68.  363.   72.  -19.]\n",
      " [-186.   72.  587. -306.]\n",
      " [  66.  -19. -306.  270.]]\n",
      "\n",
      "V\n",
      "[[ 0.27099937 -0.77804337 -0.55510939  0.11428655]\n",
      " [-0.18018525 -0.08023779 -0.17413038 -0.96476618]\n",
      " [-0.81779671 -0.47451288  0.29446638  0.13905258]\n",
      " [ 0.47465899 -0.40379194  0.75816999 -0.19190931]]\n",
      "\n",
      "Lambda\n",
      "[[842.10603029   0.           0.           0.        ]\n",
      " [  0.          33.80262392   0.           0.        ]\n",
      " [  0.           0.         107.19290412   0.        ]\n",
      " [  0.           0.           0.         356.89844167]]\n",
      "\n",
      "Reconstructed A\n",
      "[[ 120.  -68. -186.   66.]\n",
      " [ -68.  363.   72.  -19.]\n",
      " [-186.   72.  587. -306.]\n",
      " [  66.  -19. -306.  270.]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These should be the same\n"
     ]
    }
   ],
   "source": [
    "# Make a square matrix for eigendecomposition to be possible\n",
    "# Round it to make it integers to avoid having complex numbers\n",
    "A = np.round(10 * np.random.randn(4, 4))\n",
    "A = A.T @ A\n",
    "\n",
    "print('A')\n",
    "print(A)\n",
    "print()\n",
    "\n",
    "# Eigendecomposition\n",
    "evals, evecs = np.linalg.eig(A)\n",
    "\n",
    "print('V')\n",
    "print(evecs)\n",
    "print()\n",
    "\n",
    "print('Lambda')\n",
    "print(np.diag(evals))\n",
    "print()\n",
    "\n",
    "# Test reconstructing given matrix from eigenvalues eigenvectors\n",
    "Ap = evecs @ np.diag(evals) @ np.linalg.inv(evecs)\n",
    "\n",
    "print('Reconstructed A')\n",
    "print(Ap)\n",
    "print()\n",
    "\n",
    "# Visualize\n",
    "plt.subplot(121)\n",
    "plt.imshow(A)\n",
    "plt.axis('off')\n",
    "plt.title('A')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(Ap)\n",
    "plt.axis('off')\n",
    "plt.title('$V \\Lambda V^{-1}$')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('These should be the same')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7536bf5",
   "metadata": {},
   "source": [
    "## Relationship between eigenvalue and eigenvector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142f1b17",
   "metadata": {},
   "source": [
    "Distinct eigenvalues $\\lambda$'s leads to distinct eigenvectors $v$'s. But when we have the same eigenvalues (**repeated eigenvalues**), the repeated eigenvectors form the single eigenvector (producing the same vector), or the repeated eigenvectors form the **eigenplane**.\n",
    "\n",
    "For example,\n",
    "\n",
    "$$\n",
    "A =\n",
    "\\begin{bmatrix}\n",
    "3 & 1\\\\\n",
    "0 & 3\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "By **characteristic equation** to find eigenvalues,\n",
    "\n",
    "$$\n",
    "\\lambda^2 - 6 \\lambda + 9 = 0\n",
    "$$\n",
    "$$\n",
    "(\\lambda - 3)^2 = 0\n",
    "$$\n",
    "$$\n",
    "\\lambda = 3, 3\n",
    "$$\n",
    "\n",
    "When $\\lambda_1 = 3$,\n",
    "\n",
    "$$\n",
    "(A - 3 I) =\n",
    "\\begin{bmatrix}\n",
    "3 - 3 & 1\\\\\n",
    "0 & 3 - 3\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 & 1\\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 1\\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}\n",
    "v_1\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\n",
    "v_1 =\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "For $\\lambda_2$, it will have the same direction $v_2 = scaler [1, 0]$. This is the case where repeated eigenvalues for the single eigenvector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9268281",
   "metadata": {},
   "source": [
    "## Eigendecomposition of symmetric matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e6bdd3",
   "metadata": {},
   "source": [
    "Eigendecomposition of **symmetrix matrix** has the following 2 properties, assuming it has **distinct eigenvalues**\n",
    "\n",
    "1. Eigenvalues are real values, no complex numbers.\n",
    "2. Eigenvectors are all pair-wise orthogonal, meaning $V^{-1} = V^T$\n",
    "\n",
    "If two vectors are orthogonal, the dot product is 0, so start from making a dot product. Below $v_1$ and $v_2$ are eigenvectors.\n",
    "\n",
    "$$\n",
    "\\lambda_1 v_1^t v_2\n",
    "$$\n",
    "\n",
    "Because $A v_1 = \\lambda_1 v_1$,\n",
    "\n",
    "$$\n",
    "\\lambda_1 v_1^t v_2 = (A v_1)^T v_2\n",
    "$$\n",
    "\n",
    "By **LIVE EVIL rule**,\n",
    "\n",
    "$$\n",
    "\\lambda_1 v_1^t v_2 = (A v_1)^T v_2 = v_1^T A^T v_2\n",
    "$$\n",
    "\n",
    "Because a given matrix is symmetrix ($A^T = A$), and because $A v_2 = \\lambda_2 v_2$,\n",
    "\n",
    "$$\n",
    "\\lambda_1 v_1^t v_2 = (A v_1)^T v_2 = v_1^T A^T v_2 = v_1^T A v_2 = v_1^T \\lambda_2 v_2 \n",
    "$$\n",
    "\n",
    "Becuase $\\lambda_2$ is a scalar and we can move it forward by changing order,\n",
    "\n",
    "$$\n",
    "\\lambda_1 v_1^t v_2 = (A v_1)^T v_2 = v_1^T A^T v_2 = v_1^T A v_2 = v_1^T \\lambda_2 v_2 = \\lambda_2 v_1^T v_2  \n",
    "$$\n",
    "\n",
    "Extract the first and the last expression,\n",
    "\n",
    "$$\n",
    "\\lambda_1 v_1^T v_2 = \\lambda_2 v_1^T v_2  \n",
    "$$\n",
    "$$\n",
    "\\lambda_1 v_1^T v_2 - \\lambda_2 v_1^T v_2 = 0\n",
    "$$\n",
    "$$\n",
    "(\\lambda_1 - \\lambda_2) v_1^T v_2 = 0\n",
    "$$\n",
    "\n",
    "Because eigenvalues are distinct, $\\lambda_1$ and $\\lambda_2$ won't be the same, so $(\\lambda_1 - \\lambda_2)$ is not 0. For the right hand side of the above equation to be 0, $v_1^T v_2$ needs to be 0. When a dot product is 0, those vectors are orthogonal, so $v_1$ and $v_2$ are orthogonal. So **symmetrix matrix has orthogonal eigenvectors as long as eigenvalues are distinct**.\n",
    "\n",
    "It means that $V^T V$ gives a diagonal matrix, because row and columns are orthogonal. By default eigenvectors are not guaranteed to be a unit vector (not normalized to be the length of a vector 1). But when we normalize each columns of a matrix with eigenvectors in columns, pair-wise dot product produces 1, so from a matrix of eigenvectors $V$,\n",
    "\n",
    "$$\n",
    "V^T V = 1\n",
    "$$\n",
    "\n",
    "Because $A^{-1} A = I$,\n",
    "\n",
    "$$\n",
    "V^T = V^{-1}\n",
    "$$\n",
    "\n",
    "It means that we don't need to do inverse calculation (difficult compute and time consuming). We can replace it with just a transpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0af26810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "[[-3.3 -1.2 -2.4  0.2  0.3]\n",
      " [-1.2  2.4  0.3 -0.5 -0.1]\n",
      " [-2.4  0.3  1.2 -0.8  1.6]\n",
      " [ 0.2 -0.5 -0.8  1.9  0.1]\n",
      " [ 0.3 -0.1  1.6  0.1 -3.9]]\n",
      "\n",
      "Confirm, by default, numpy normalizes the eigenvectors\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEsUlEQVR4nO3aIahedRzH4d/xXhGLrNiGimDQZLFpWBRBBWXBoQOxGY0mg1XEYF4yiM0iJsGiwckEtSiWBQVhYSZxHsOW5HK5L+/Y+dzL88AN93/Kt3z4Hw7vsq7rAD33bT0AOJo4IUqcECVOiBInRIkTosQJUeI8Q5Zl+WpZlhvLsjyw9Rb2J84zYlmWx2bmuZlZZ+bFbddwN4jz7HhjZr6ZmSszc3nbKdwNi5/vnQ3LsvwyMx/MzLdzO9Lz67r+se0q9uHmPAOWZXl2Zh6dmU/Xdf1uZn6dmde2XcW+xHk2XJ6ZL9d1/fPO/5+MV9tTz2vtKbcsy4Mz8/vMHMzMX3eOH5iZczPz9Lqu1zaaxp7cnKffyzNza2aempmn7/w9OTNfz+2PRJxSbs5TblmWL2bmx3Vd3/nf+cWZ+Whufxj6Z5Nx7EWcEOW1FqLECVHihChxQtThcQ+ff/ydU/O16LdL57eesJOHr52uD6g33rq59YQTu//g1tYTdvL9C+8vR527OSFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IOjzu4W+Xzt+rHXv76e2Pt56wk2euXtx6wk5uXj+39YQTO3jo760n3BVuTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEHR738OFr/9yrHXt75urFrSfs5KVHfth6wk6u/Hxh6wkn9t6Fz7eesKN3jzx1c0KUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQdXjcwxtv3bxXO/Z28/q5rSfs5MrPF7aesJPPXv1w6wkndunqm1tP2MnrTxx97uaEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtThcQ/vP7h1r3bs7eChv7eesJP3Lny+9YSdXLr65tYTTuz8Kz9uPWE3/x597OaEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IWpZ13XrDcAR3JwQJU6IEidEiROixAlR4oSo/wA4O2oRmxFwhwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD7CAYAAACR4IPAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEnklEQVR4nO3av6pl5RnA4ffTY+kNHEg5BGKEI3gPBwKCrWUuII1gZZXOQq8ggUiKNLmCIY2tVgPOhJSicLAXlBSZz2JmZMDJMGf+uH57fJ7q7LX3By8LfvtlH9baew/Q88rRAwCPJk6IEidEiROixAlR4oQocUKUOF8Ca60/rbU+W2t9tda6ff/v94+ei2ezPITw8lhr/XVm/rL3/vzoWXh2NufL5Xcz8++jh+D5EGfcWuvVtdYPa603H/HeP9Zanz506fW993dPcY6gs6MH4PH23v9ba/1n7m3FLx9cX2u9PTPvzMxv77/+zcx8c91zdNmcp+H23IvsYR/PzCd776v7r9+YmTtPcY4om/M03JmZtx+8WGu9MzM3ZuYPD33mjfn5780nOUeUzXkaftqAa61XZ+ajmflw7/39gw/svT/Ze//tuufosjlPw52ZubHWem1m/jgz/52Zv7/AcwSI8zR8NffCemtm/jwz7+29777AcwR4COFErLW+mHtfpl/vvd990ec4nt+cp+P2zPx+Zj74hc5xMJsTomxOiBInRIkTosQJUeKEqMc+hHD32xsn86/cy/OLo0eAp/Kvu/9cj7puc0KUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQdfa4Ny/PL36hMZ7dzatbR49wLad0bzmGzQlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEqLOjB3heLs8vjh7hWm5e3Tp6hGs5tfv7MrA5IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTog6O3qAX6vL84ujR7iWm1e3jh7hiZ3avf1/bE6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRJ0dPQCn4fL84ugRntjNq1tHj/Bc2JwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRK2999EzAI9gc0KUOCFKnBAlTogSJ0SJE6J+BEvyiwJu+8p5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V^T V is an identity matrix\n",
      "[[ 1.  0.  0. -0.  0.]\n",
      " [ 0.  1. -0.  0. -0.]\n",
      " [ 0. -0.  1.  0. -0.]\n",
      " [-0.  0.  0.  1.  0.]\n",
      " [ 0. -0. -0.  0.  1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make a symmetic matrix by addition method (it can be replaced with A^T @ A)\n",
    "A = np.random.randn(5, 5)\n",
    "A = A + A.T\n",
    "\n",
    "print('A')\n",
    "print(np.round(A, 1))\n",
    "print()\n",
    "\n",
    "# Get eigenvector\n",
    "evals, evecs = np.linalg.eig(A)\n",
    "\n",
    "# Confirm, by default, numpy normalizes the eigenvectors\n",
    "print('Confirm, by default, numpy normalizes the eigenvectors')\n",
    "print(np.sqrt(sum(evecs ** 2)))\n",
    "\n",
    "# Visualize V^T V\n",
    "plt.imshow(A)\n",
    "plt.axis('off')\n",
    "plt.title('A')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(evecs)\n",
    "plt.axis('off')\n",
    "plt.title('Eigenvectors')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(evecs.T @ evecs)\n",
    "plt.axis('off')\n",
    "plt.title('$V^T V$')\n",
    "plt.show()\n",
    "\n",
    "print('V^T V is an identity matrix')\n",
    "print(np.round(evecs.T @ evecs, 1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ade2d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "[[ 0.1  0.6 -1.   0.8 -0.3]\n",
      " [-0.1  1.2 -0.8  0.7  0.8]\n",
      " [-0.4  1.4  0.6  0.8 -2.2]\n",
      " [ 1.9  1.   0.2  2.1  0.3]\n",
      " [-2.1  0.7 -2.3 -1.1 -1.9]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAAD3CAYAAADmIkO7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAEwElEQVR4nO3aMYtm5R2H4f/ZDJlN4y5uacSF2MTKLkW0jVok2JjCwmX9BmIZ8gUiCFqGFKksDLZRrERBVEhhEQKSBMUtskSiyOKGoByL3Upml3mZIed+x+uCKeY8za+5eQ6Hd1nXdYCec1sPAI4mTogSJ0SJE6LECVHihChxQpQ4z5BlWd5aluXzZVkOt97CyYnzjFiW5fLMPDoz68z8ats1nAZxnh3PzMx7M/PHmbmy7RROw+Lne2fDsix/n5kXZ+b9uRXpj9d1vb7tKk7CzXkGLMvyyMw8MDOvruv6l5n5x8w8ve0qTkqcZ8OVmXlzXdfPbv//yni13Xtea/fcsiw/mpl/zcwPZubG7ceHM3NxZh5e1/XDjaZxQm7O/ffkzHwzMw/NzMO3/346M+/MrY9E7Ck3555bluWNmfnruq7Pf+f5r2fm5bn1YejrTcZxIuKEKK+1ECVOiBInRIkTog7udvjA71/Ym69F9973xdYTdnLw6qWtJ+zk0rOfbD3h2P759uWtJ+zko98+txz13M0JUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQtTB3Q7PfbU/7T5x/9+2nrCTN84/svWEndz43+HWE47tvp9f23rCqdif+uB7RpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcEHVwt8Mffrk/7T54/vrWE3Zy7snPtp6wk3sO/7v1hGP7+rH/bD1hNzePfrw/9cH3jDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcEHVwt8M/X/3d/2vHif3m2i+3nrCTf1+/sPWEnXzw+J+2nnBsP/nD1a0nnAo3J0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROilnVd73j42IVn73wYc/O1S1tP2MnhLz7eesJObjz1s60nHNvFdz/desJOXv/0peWo525OiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6KWdV233gAcwc0JUeKEKHFClDghSpwQJU6I+hYfuGuOjwMbrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For eigenvectors from non-symmetrix matrix, V^T V is not an identity matrix\n",
      "[[1. +0.j  0.1+0.j  0.1-0.j  0.1+0.j  0.4+0.j ]\n",
      " [0.1+0.j  0.6+0.2j 1. +0.j  0.3-0.j  0.4-0.1j]\n",
      " [0.1-0.j  1. +0.j  0.6-0.2j 0.3+0.j  0.4+0.1j]\n",
      " [0.1+0.j  0.3-0.j  0.3+0.j  1. +0.j  0.4+0.j ]\n",
      " [0.4+0.j  0.4-0.1j 0.4+0.1j 0.4+0.j  1. +0.j ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make a non-symmetic matrix to confirm it doesn't produce identity matrix by V^T V\n",
    "A = np.random.randn(5, 5)\n",
    "\n",
    "print('A')\n",
    "print(np.round(A, 1))\n",
    "print()\n",
    "\n",
    "# Get eigenvector\n",
    "evals, evecs = np.linalg.eig(A)\n",
    "\n",
    "# # Confirm, by default, numpy normalizes the eigenvectors\n",
    "# print('Confirm, by default, numpy normalizes the eigenvectors')\n",
    "# print(np.sqrt(sum(evecs ** 2)))\n",
    "\n",
    "# Visualize V^T V\n",
    "plt.imshow(A)\n",
    "plt.axis('off')\n",
    "plt.title('A')\n",
    "plt.show()\n",
    "\n",
    "# Not easy to visualize it because eigenvectors of non-sysmmetric matrix contain complex numbers\n",
    "# plt.imshow(evecs)\n",
    "# plt.axis('off')\n",
    "# plt.title('Eigenvectors')\n",
    "# plt.show()\n",
    "\n",
    "# plt.imshow(evecs.T @ evecs)\n",
    "# plt.axis('off')\n",
    "# plt.title('$V^T V$')\n",
    "# plt.show()\n",
    "\n",
    "print('For eigenvectors from non-symmetrix matrix, V^T V is not an identity matrix')\n",
    "print(np.round(evecs.T @ evecs, 1))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201ccf04",
   "metadata": {},
   "source": [
    "## Eigenlayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db52bee",
   "metadata": {},
   "source": [
    "From a given square matrix $A$, either a symmetrix matrix or non-symmetrix matrix, eigendecomposition and diagonalization of the matrix gives us the following\n",
    "\n",
    "$$\n",
    "A = V \\Lambda V^{-1}\n",
    "$$\n",
    "\n",
    "$V$ is a matrix with **eigenvectors** in each column, and $\\Lambda$ is a diagonal matrix with **eigenvalues** in each diagonal element. From one eigenvector $v_i$ and the corresponding eigenvalue $\\lambda_i$ from the decomposition, we can create a matrix like below\n",
    "\n",
    "$$\n",
    "v_i \\lambda_i v_i^{-1} = A_i\n",
    "$$\n",
    "\n",
    "Because $V^{-1} = V^T$ and $v_i^{-1} = v_i^t$,\n",
    "\n",
    "$$\n",
    "v_i \\lambda_i v_i^{T} = A_i\n",
    "$$\n",
    "\n",
    "This is a column vector ($v_i$, mx1) times a row vector ($v_i^{T}$, 1xm), scaled by $\\lambda_i$, giving us a matrix (mxm). It's actually an **outer product** of an eigenvector. We can think of this one matrxi as one layer of the given matrix $A$. If we wanna reconstruct $A$ (mxn), we can use the following equation.\n",
    "\n",
    "$$\n",
    "A = \\sum_{i=1}^{n} v_i \\lambda_i v_i^{-1} = \\sum_{i=1}^{n} v_i \\lambda_i v_i^{T}\n",
    "$$\n",
    "\n",
    "We can arbitrarily choose a number $n$ as long as it doesn't exceed $n$. So it means that we can only sum the first 1 to $i$ layers to recontruct $A$.\n",
    "\n",
    "**Numpy** (and most of the other softwares) by default normalizes eigenvectors to have a unit length. It means that $V V^{-1}$ gives the matrix which has all 1s in the diagonal elements, because each pair of vectors are orthogonal. So the magnitude of each eigenvector is 1. It means eigenvectors $v_i$ only give us the direction. And eigenvalues $\\lambda_i$ give us the importance  of each eigenvector.\n",
    "\n",
    "$$\n",
    "||v_i|| = 1\n",
    "$$\n",
    "$$\n",
    "||\\lambda_i|| \\neq 1\n",
    "$$\n",
    "\n",
    "**Eigenvectors** point in the **important direction** in the space of matrix $A$, and **eigenvalues** tell us **how important** those specific directions are. The larger the magnitude of eigenvalue is, the more important the direction is in the space of matrix $A$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6dfef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "[[ 75.   9.  17. -35.   9.]\n",
      " [  9.  44.  15. -19.  13.]\n",
      " [ 17.  15.  49. -31.  11.]\n",
      " [-35. -19. -31.  36. -27.]\n",
      " [  9.  13.  11. -27.  45.]]\n",
      "\n",
      "One eigenvector v\n",
      "(5,)\n",
      "[-0.74457964  0.42862271  0.25344267 -0.09133395  0.43509614]\n",
      "\n",
      "Outer product of v\n",
      "[[ 0.6 -0.3 -0.2  0.1 -0.3]\n",
      " [-0.3  0.2  0.1 -0.   0.2]\n",
      " [-0.2  0.1  0.1 -0.   0.1]\n",
      " [ 0.1 -0.  -0.   0.  -0. ]\n",
      " [-0.3  0.2  0.1 -0.   0.2]]\n",
      "\n",
      "Magnitude of outer product of v\n",
      "0.9999999999999998\n",
      "\n",
      "Corresponding eigenvalue\n",
      "54.48012201754042\n",
      "\n",
      "Outer product of v scaled by corresponding eigenvalue\n",
      "[[ 30.2 -17.4 -10.3   3.7 -17.6]\n",
      " [-17.4  10.    5.9  -2.1  10.2]\n",
      " [-10.3   5.9   3.5  -1.3   6. ]\n",
      " [  3.7  -2.1  -1.3   0.5  -2.2]\n",
      " [-17.6  10.2   6.   -2.2  10.3]]\n",
      "\n",
      "Magnitude of outer product of v scaled by eigenvalue\n",
      "54.48012201754041\n",
      "\n",
      "i: 0, rank: 1\n",
      "i: 1, rank: 2\n",
      "i: 2, rank: 3\n",
      "i: 3, rank: 4\n",
      "i: 4, rank: 5\n",
      "\n",
      "A\n",
      "[[ 75.   9.  17. -35.   9.]\n",
      " [  9.  44.  15. -19.  13.]\n",
      " [ 17.  15.  49. -31.  11.]\n",
      " [-35. -19. -31.  36. -27.]\n",
      " [  9.  13.  11. -27.  45.]]\n",
      "\n",
      "A reconstructed\n",
      "[[ 75.   9.  17. -35.   9.]\n",
      " [  9.  44.  15. -19.  13.]\n",
      " [ 17.  15.  49. -31.  11.]\n",
      " [-35. -19. -31.  36. -27.]\n",
      " [  9.  13.  11. -27.  45.]]\n",
      "\n",
      "A - A reconstructed\n",
      "[[-0. -0. -0.  0.  0.]\n",
      " [-0.  0. -0. -0.  0.]\n",
      " [-0. -0.  0.  0. -0.]\n",
      " [ 0. -0.  0. -0.  0.]\n",
      " [ 0.  0. -0.  0. -0.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a matrix A\n",
    "m = 5\n",
    "A = np.random.randn(m, m)\n",
    "\n",
    "# To work with only real values in eigendecomposition, make it symmetrix matrix\n",
    "A = np.round(10 * A.T @ A)\n",
    "\n",
    "print('A')\n",
    "print(A)\n",
    "print()\n",
    "\n",
    "# Eigendecomposition\n",
    "D, V = np.linalg.eig(A)\n",
    "\n",
    "# Create one layer by one eigenvalue and eigenvector\n",
    "i = 2\n",
    "v = V[:, i]\n",
    "op = np.outer(v, v)\n",
    "op_scaled = D[i] * np.outer(v, v)\n",
    "\n",
    "print('One eigenvector v')\n",
    "print(v.shape)\n",
    "print(v)\n",
    "print()\n",
    "\n",
    "print('Outer product of v')\n",
    "print(np.round(op, 1))\n",
    "print()\n",
    "\n",
    "print('Magnitude of outer product of v')\n",
    "print(np.linalg.norm(op))\n",
    "print()\n",
    "\n",
    "print('Corresponding eigenvalue')\n",
    "print(D[i])\n",
    "print()\n",
    "\n",
    "print('Outer product of v scaled by corresponding eigenvalue')\n",
    "print(np.round(op_scaled, 1))\n",
    "print()\n",
    "\n",
    "print('Magnitude of outer product of v scaled by eigenvalue')\n",
    "print(np.linalg.norm(op_scaled))\n",
    "print()\n",
    "\n",
    "# Reconstruct the given matrix A from eigenlayers\n",
    "Arecon = np.zeros((m, m))\n",
    "\n",
    "for i in range(m):\n",
    "    \n",
    "    # Get eigenvector\n",
    "    v = np.reshape(V[:, i], (m, 1))\n",
    "\n",
    "    # Sum up each eigenlayer by outer product of eigenvector and scale by eigenvalue\n",
    "    Arecon += v * D[i] * v.T\n",
    "    \n",
    "    # Check in each sum, rank of matrix increase\n",
    "    print(f'i: {i}, rank: {np.linalg.matrix_rank(Arecon)}')\n",
    "    \n",
    "print()\n",
    "print('A')\n",
    "print(A)\n",
    "print()\n",
    "\n",
    "print('A reconstructed')\n",
    "print(np.round(Arecon))\n",
    "print()\n",
    "\n",
    "print('A - A reconstructed')\n",
    "print(np.round(A - Arecon))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d95446",
   "metadata": {},
   "source": [
    "## Eigendecomposition of singular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe0ca8f",
   "metadata": {},
   "source": [
    "Eigendecomposition can also be applied to **singular matrix** (non-invertible matrix, its determinant is 0). In such case, there will be at least one 0 eigenvalue. The **determinant** is equal to the **product** of all **eigenvalues**. So to know the rank of a singular matrix, we can count the number of non-zero eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aeb245e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "Shape of A: (7, 7)\n",
      "Rank of A: 7\n",
      "[[-0.7 -0.8  1.4  0.7 -0.2  1.1 -1.1]\n",
      " [ 1.3 -0.8  1.6 -0.9  1.2  2.7  1. ]\n",
      " [-0.4  0.3 -2.2 -0.4  0.3 -1.1  0.9]\n",
      " [-1.4  0.3  0.4 -1.   1.8 -1.3  0.2]\n",
      " [-0.3 -0.5  0.5 -0.8 -0.6 -1.1 -0.5]\n",
      " [-0.3  1.6 -1.  -0.5  0.6 -1.2  0.1]\n",
      " [-0.3  1.   0.4  1.2 -0.2  1.3 -0. ]]\n",
      "\n",
      "Eigenvalue\n",
      "[-3.25747976+0.j          0.97910402+0.j          0.87007484+0.j\n",
      " -1.07633039+1.64128456j -1.07633039-1.64128456j -1.14150372+0.j\n",
      " -1.95358794+0.j        ]\n",
      "\n",
      "Trace: -6.656053343562339\n",
      "Sum of all eigenvalues: (-6.65605334356234+0j)\n",
      "\n",
      "Determinant: -23.83953615616962\n",
      "Product of all eigenvalues: (-23.839536156169533+0j)\n",
      "\n",
      "A\n",
      "Shape of A: (7, 7)\n",
      "Rank of A: 5\n",
      "[[ 0.3 -0.8  1.5 -0.3  1.2 -1.7 -0.7]\n",
      " [ 1.9 -2.5  0.5  2.9  1.   0.9  2.2]\n",
      " [ 0.9 -1.8  2.5 -0.1  1.5 -1.9  0.7]\n",
      " [ 2.3  0.4  0.6  1.6  0.8  0.7  1.8]\n",
      " [-0.4 -0.  -0.   0.9 -0.4  0.5 -0. ]\n",
      " [-0.8  5.6 -1.5  0.5 -2.2  2.1 -1.1]\n",
      " [ 0.8 -3.1  3.   2.7  2.9 -2.9 -2.1]]\n",
      "\n",
      "Eigenvalue\n",
      "[ 4.04098645e+00+2.22567325j  4.04098645e+00-2.22567325j\n",
      " -3.93838766e+00+0.j         -2.55555671e+00+0.j\n",
      " -7.47622756e-02+0.j         -1.39082661e-14+0.j\n",
      " -7.87244129e-16+0.j        ]\n",
      "\n",
      "Trace: 1.513266247560113\n",
      "Sum of all eigenvalues: (1.513266247560115+0j)\n",
      "Traces are the same\n",
      "\n",
      "Determinant: 1.8778595602488494e-29\n",
      "Product of all eigenvalues: (-1.7534997128702655e-28+0j)\n",
      "Determinants are the same, but they are 0, because at least one eigenvalue is 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a full rank matrix\n",
    "A = np.random.randn(7, 7)\n",
    "tr = np.matrix.trace(A)\n",
    "dt = np.linalg.det(A)\n",
    "l = np.linalg.eig(A)[0]\n",
    "\n",
    "print('A')\n",
    "print(f'Shape of A: {A.shape}')\n",
    "print(f'Rank of A: {np.linalg.matrix_rank(A)}')\n",
    "print(np.round(A, 1))\n",
    "print()\n",
    "\n",
    "print('Eigenvalue')\n",
    "print(l)\n",
    "print()\n",
    "\n",
    "print(f'Trace: {tr}')\n",
    "print(f'Sum of all eigenvalues: {sum(l)}')\n",
    "print()\n",
    "\n",
    "print(f'Determinant: {dt}')\n",
    "print(f'Product of all eigenvalues: {np.prod(l)}')\n",
    "print()\n",
    "\n",
    "# Create a singular matrix\n",
    "A = np.random.randn(7, 5) @ np.random.randn(5, 7)\n",
    "tr = np.matrix.trace(A)\n",
    "dt = np.linalg.det(A)\n",
    "l = np.linalg.eig(A)[0]\n",
    "\n",
    "print('A')\n",
    "print(f'Shape of A: {A.shape}')\n",
    "print(f'Rank of A: {np.linalg.matrix_rank(A)}')\n",
    "print(np.round(A, 1))\n",
    "print()\n",
    "\n",
    "print('Eigenvalue')\n",
    "print(l)\n",
    "print()\n",
    "\n",
    "print(f'Trace: {tr}')\n",
    "print(f'Sum of all eigenvalues: {sum(l)}')\n",
    "print('Traces are the same')\n",
    "print()\n",
    "\n",
    "print(f'Determinant: {dt}')\n",
    "print(f'Product of all eigenvalues: {np.prod(l)}')\n",
    "print('Determinants are the same, but they are 0, because at least one eigenvalue is 0')\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-machine-learning",
   "language": "python",
   "name": "env-machine-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
