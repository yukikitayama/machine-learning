{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "551ec35a",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e71d6ca",
   "metadata": {},
   "source": [
    "## Rejection reason\n",
    "\n",
    "### Question\n",
    "\n",
    "Suppose we have a binary classification model that classifies whether or not an applicant should be qualified to get a loan. Because we are a financial company, we have to provide each rejected applicant with a reason why. Given we don’t have access to the feature weights, how would we give each rejected applicant a reason why they got rejected?\n",
    "\n",
    "### Answer\n",
    "\n",
    "Create **partial dependence plot** for each feature and find the value in a feature which increases the probability of default, and explain to applicants that their input to a certain feature possibly was the reason for rejection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebfe928",
   "metadata": {},
   "source": [
    "## Keyword bidding\n",
    "\n",
    "### Question\n",
    "\n",
    "Let’s say you’re working on keyword bidding optimization. You’re given a dataset with two columns. One column contains the keywords that are being bid against, and the other column contains the price that’s being paid for those keywords. Given this dataset, how would you build a model to bid on a new unseen keyword?\n",
    "\n",
    "### Answer\n",
    "\n",
    "We need to build a supervised learning algorithm which takes keyword column as input and outputs the bidding price.\n",
    "\n",
    "We make word embeddings where similar words have a similar representation in the form of vectors.\n",
    "\n",
    "Take cosine similarity of words to a target word and recommend prices of the similar words.\n",
    "\n",
    "Todo: GloVe embedding, Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbca689",
   "metadata": {},
   "source": [
    "## 85% vs 82%\n",
    "\n",
    "### Question\n",
    "\n",
    "We have two models: one with 85% accuracy, one 82%. Which one do you pick?\n",
    "\n",
    "### Answer\n",
    "\n",
    "We need to know whether a higher accuracy or a higher interpretable model is important to the business, because 85% accuracy model could be from a blackbox model and 82% accuracy model could be linear regression.\n",
    "\n",
    "If this model is a binary classification model, and recall or precision are important to the business, we might pick a model regardless of the accuracy. 82% accuracy model could have a higher recall or precision than 85% accuracy model.\n",
    "\n",
    "We also need to know the scalability. 85% accuracy model could have too long training time and model could use too much memory, so that 85% accuracy model cannot be used in production environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f32f4",
   "metadata": {},
   "source": [
    "## Multicollinearity in regression\n",
    "\n",
    "### Question\n",
    "\n",
    "How would you tackle multicollinearity in multiple linear regression?\n",
    "\n",
    "### Answer\n",
    "\n",
    "Ignore multicollinearity, if the predictions work in training and test dateset, and the correlation of variables are not that high.\n",
    "\n",
    "If the multicollinearity is caused by higher-order terms, standardize the variables.\n",
    "\n",
    "Reduce the number of vairables. Remove one of the highly correlated variables. Apply PCA to reduce the dimension.\n",
    "\n",
    "### Resource\n",
    "\n",
    "- [When Do You Need to Standardize the Variables in a Regression Model?](https://statisticsbyjim.com/regression/standardize-variables-regression/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1618c5ea-1248-4cd7-ba7e-860a3a33e283",
   "metadata": {},
   "source": [
    "## Variate anomalies\n",
    "\n",
    "### Question\n",
    "\n",
    "If given a univariate dataset, how would you design a function to detect anomalies? What if the data is bivariate?\n",
    "\n",
    "### Answer\n",
    "\n",
    "In a function, it can find the values at the 1th and 99th percentiles for example, and eliminate all values below or above those thresholds. In a bivariate data, anomaly detection can be one variable individually, or a combination of 2 variables. The example of anomaly detection machine learning algorithm is **Isolation Forecast**, **DBSCAN**, **Bayesian Gaussian Mixture**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a0fba-c1b6-40d0-afc4-26422b38b4d5",
   "metadata": {},
   "source": [
    "## Explaining linear regression to different audiences\n",
    "\n",
    "### Question\n",
    "\n",
    "How would you explain the concept of linear regression to a child, a first-year college student and a mathematician?\n",
    "\n",
    "### Answer\n",
    "\n",
    "To child, draw a lot of points, and draw one straight line in the center of the group of points.\n",
    "\n",
    "To college student, linear regression is a statistical model to predict numbers. It's a way to draw a straight line in a scatter plot of data points, such that the straight line minimizes the distance between the actual data and the predicted data.\n",
    "\n",
    "To mathematician, linear regression is a method to model relationship between a dependent variable $y$ and one or more independent variables $X$. The method assumes the linear relationship between $y$ and $X$, so that $y$ will be calculated by a linear combination of $X$. This linear combination minimizes the distance between the actual values and predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445415e-1dc0-422f-9af5-8fcaecf80522",
   "metadata": {},
   "source": [
    "## Credit card fraud model\n",
    "\n",
    "### Question\n",
    "\n",
    "Say you work at a major credit card company and are given a dataset of 600,000 credit card transactions. Use this dataset to build a fraud detection model.\n",
    "\n",
    "### Answer\n",
    "\n",
    "Clarify the definition of a transaction which was labeled as a fraud; User decided or bank decided? \n",
    "\n",
    "Check how frequent the fraud data is in the dataset. Probably, fraud is small, so implement rebalancing methods, such as up-sampling, down-sampling or SMOTE.\n",
    "\n",
    "Perform feature engineering, such as time of data for transaction, \n",
    "\n",
    "https://www.interviewquery.com/questions/credit-card-fraud-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f11364-6182-4e84-975f-79fa55f1335a",
   "metadata": {},
   "source": [
    "## Pizza no show\n",
    "\n",
    "### Question\n",
    "\n",
    "You run a pizza shop, and you run into a lot of no-shows after customers place their order. What features would you include in a model to try to predict a no-show?\n",
    "\n",
    "### Answer\n",
    "\n",
    "Some of the following variables may be difficult to obtain. It depends on discussion with business team and technical team about the feasibility of getting those data.\n",
    "\n",
    "For business level, order type (call, online, in-person), employee administering order, order cost, projected time to complete order, time of day of orders, recept type (deliver, pick up)\n",
    "\n",
    "For customer level, area of customer, time length of a order (in call, in website), new or existing customer\n",
    "\n",
    "For environmental level, day of the week, temperature, weather."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edf70f9-0e4d-41a7-84bf-bcf2cbb527ff",
   "metadata": {},
   "source": [
    "## Search Algorithm Recall\n",
    "\n",
    "### Question\n",
    "\n",
    "Let's say you work as a data scientist at Amazon. You want to improve the search results for product search but cannot change the underlying logic in the search algorithm. What methods could you use to increase recall?\n",
    "\n",
    "### Answer\n",
    "\n",
    "Recall is\n",
    "\n",
    "$$\n",
    "\\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "Reduce threshold to predict more positive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509bc986-ae74-4593-b6e6-e8501350f148",
   "metadata": {},
   "source": [
    "## Missing housing date\n",
    "\n",
    "### Question\n",
    "\n",
    "We want to build a model to predict housing prices in a city. We've scraped 100,000 listings over the past 3 years but found that around 20% of the listings are missing square footage data. How do we deal with the missing data to construct our model?\n",
    "\n",
    "### Answer\n",
    "\n",
    "Idea of model **without square footage**. I assume the square footage is an important feature to predict housing prices. But we can explore whether we can build a model without a square footage. For example, we remove the rows of data with the missing square footage, and build 2 models; one with square footage and with other features, and the other model without square footage but with the other features. If model accuracy doesn't decrease so much without square footage, we could build a model without square footage. But it's unlikely though.\n",
    "\n",
    "Idea of **deleting** the rows of data with missing square footage. We would remove the rows of data with missing square footage. I call this data 80% data. Build 2 models; one with this 80% data with complete square footage, and the other with reducing another 20% data (I cann this data 60% data) and build the same stats model with complete square footage. If model accuracy from 60% data is slightly less accurate than 80% data model, we may be able to just delete the rows of data with missing square footage.\n",
    "\n",
    "Idea of not delete data and **impute** missing values. We could fill in the missing values with estimations. Simple estimation is the mean or median of the distribution of square footage. Another estimation is **k nearest neighbors algorithm** to approximate a square footage based on grouping different categorical features. We can also get means from different subsets of data by group by data by other features such as locations, number of bedrooms"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
