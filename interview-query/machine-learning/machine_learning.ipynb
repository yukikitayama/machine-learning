{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "551ec35a",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e71d6ca",
   "metadata": {},
   "source": [
    "## Rejection reason\n",
    "\n",
    "### Question\n",
    "\n",
    "Suppose we have a binary classification model that classifies whether or not an applicant should be qualified to get a loan. Because we are a financial company, we have to provide each rejected applicant with a reason why. Given we don’t have access to the feature weights, how would we give each rejected applicant a reason why they got rejected?\n",
    "\n",
    "### Answer\n",
    "\n",
    "Create **partial dependence plot** for each feature and find the value in a feature which increases the probability of default, and explain to applicants that their input to a certain feature possibly was the reason for rejection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebfe928",
   "metadata": {},
   "source": [
    "## Keyword bidding\n",
    "\n",
    "### Question\n",
    "\n",
    "Let’s say you’re working on keyword bidding optimization. You’re given a dataset with two columns. One column contains the keywords that are being bid against, and the other column contains the price that’s being paid for those keywords. Given this dataset, how would you build a model to bid on a new unseen keyword?\n",
    "\n",
    "### Answer\n",
    "\n",
    "We need to build a supervised learning algorithm which takes keyword column as input and outputs the bidding price.\n",
    "\n",
    "We make word embeddings where similar words have a similar representation in the form of vectors.\n",
    "\n",
    "Take cosine similarity of words to a target word and recommend prices of the similar words.\n",
    "\n",
    "Todo: GloVe embedding, Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbca689",
   "metadata": {},
   "source": [
    "## 85% vs 82%\n",
    "\n",
    "### Question\n",
    "\n",
    "We have two models: one with 85% accuracy, one 82%. Which one do you pick?\n",
    "\n",
    "### Answer\n",
    "\n",
    "We need to know whether a higher accuracy or a higher interpretable model is important to the business, because 85% accuracy model could be from a blackbox model and 82% accuracy model could be linear regression.\n",
    "\n",
    "If this model is a binary classification model, and recall or precision are important to the business, we might pick a model regardless of the accuracy. 82% accuracy model could have a higher recall or precision than 85% accuracy model.\n",
    "\n",
    "We also need to know the scalability. 85% accuracy model could have too long training time and model could use too much memory, so that 85% accuracy model cannot be used in production environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f32f4",
   "metadata": {},
   "source": [
    "## Multicollinearity in regression\n",
    "\n",
    "### Question\n",
    "\n",
    "How would you tackle multicollinearity in multiple linear regression?\n",
    "\n",
    "### Answer\n",
    "\n",
    "Ignore multicollinearity, if the predictions work in training and test dateset, and the correlation of variables are not that high.\n",
    "\n",
    "If the multicollinearity is caused by higher-order terms, standardize the variables.\n",
    "\n",
    "Reduce the number of vairables. Remove one of the highly correlated variables. Apply PCA to reduce the dimension.\n",
    "\n",
    "### Resource\n",
    "\n",
    "- [When Do You Need to Standardize the Variables in a Regression Model?](https://statisticsbyjim.com/regression/standardize-variables-regression/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1618c5ea-1248-4cd7-ba7e-860a3a33e283",
   "metadata": {},
   "source": [
    "## Variate anomalies\n",
    "\n",
    "### Question\n",
    "\n",
    "If given a univariate dataset, how would you design a function to detect anomalies? What if the data is bivariate?\n",
    "\n",
    "### Answer\n",
    "\n",
    "In a function, it can find the values at the 1th and 99th percentiles for example, and eliminate all values below or above those thresholds. In a bivariate data, anomaly detection can be one variable individually, or a combination of 2 variables. The example of anomaly detection machine learning algorithm is **Isolation Forecast**, **DBSCAN**, **Bayesian Gaussian Mixture**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28a0fba-c1b6-40d0-afc4-26422b38b4d5",
   "metadata": {},
   "source": [
    "## Explaining linear regression to different audiences\n",
    "\n",
    "### Question\n",
    "\n",
    "How would you explain the concept of linear regression to a child, a first-year college student and a mathematician?\n",
    "\n",
    "### Answer\n",
    "\n",
    "To child, draw a lot of points, and draw one straight line in the center of the group of points.\n",
    "\n",
    "To college student, linear regression is a statistical model to predict numbers. It's a way to draw a straight line in a scatter plot of data points, such that the straight line minimizes the distance between the actual data and the predicted data.\n",
    "\n",
    "To mathematician, linear regression is a method to model relationship between a dependent variable $y$ and one or more independent variables $X$. The method assumes the linear relationship between $y$ and $X$, so that $y$ will be calculated by a linear combination of $X$. This linear combination minimizes the distance between the actual values and predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445415e-1dc0-422f-9af5-8fcaecf80522",
   "metadata": {},
   "source": [
    "## Credit card fraud model\n",
    "\n",
    "### Question\n",
    "\n",
    "Say you work at a major credit card company and are given a dataset of 600,000 credit card transactions. Use this dataset to build a fraud detection model.\n",
    "\n",
    "### Answer\n",
    "\n",
    "Clarify the definition of a transaction which was labeled as a fraud; User decided or bank decided? \n",
    "\n",
    "Check how frequent the fraud data is in the dataset. Probably, fraud is small, so implement rebalancing methods, such as up-sampling, down-sampling or SMOTE.\n",
    "\n",
    "Perform feature engineering, such as time of data for transaction, \n",
    "\n",
    "https://www.interviewquery.com/questions/credit-card-fraud-model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f11364-6182-4e84-975f-79fa55f1335a",
   "metadata": {},
   "source": [
    "## Pizza no show\n",
    "\n",
    "### Question\n",
    "\n",
    "You run a pizza shop, and you run into a lot of no-shows after customers place their order. What features would you include in a model to try to predict a no-show?\n",
    "\n",
    "### Answer\n",
    "\n",
    "Some of the following variables may be difficult to obtain. It depends on discussion with business team and technical team about the feasibility of getting those data.\n",
    "\n",
    "For business level, order type (call, online, in-person), employee administering order, order cost, projected time to complete order, time of day of orders, recept type (deliver, pick up)\n",
    "\n",
    "For customer level, area of customer, time length of a order (in call, in website), new or existing customer\n",
    "\n",
    "For environmental level, day of the week, temperature, weather."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
